"""
Simple CUI Reduction Validation Script
For immediate validation of your reduction results
"""

import numpy as np
from typing import List, Dict, Set, Tuple
from collections import Counter
import json


def quick_validate(original_cuis: List[str], reduced_cuis: List[str], text: str = None) -> Dict:
    """
    Quick validation without database dependencies
    Use this for immediate validation of your results
    """
    original_set = set(original_cuis)
    reduced_set = set(reduced_cuis)
    
    print("\n" + "="*60)
    print("CUI REDUCTION VALIDATION")
    print("="*60)
    
    if text:
        print(f"Text: {text}")
    
    # Basic statistics
    print(f"\nðŸ“Š BASIC STATISTICS:")
    print(f"   Original CUIs: {len(original_set):,}")
    print(f"   Reduced CUIs: {len(reduced_set):,}")
    print(f"   Reduction: {(1 - len(reduced_set)/len(original_set))*100:.1f}%")
    
    # Set analysis
    retained = reduced_set & original_set
    new_cuis = reduced_set - original_set
    removed = original_set - reduced_set
    
    print(f"\nðŸ”„ SET ANALYSIS:")
    print(f"   Retained from original: {len(retained):,}")
    print(f"   New CUIs introduced: {len(new_cuis):,}")
    print(f"   CUIs removed: {len(removed):,}")
    
    # Quality indicators
    print(f"\nâœ… QUALITY INDICATORS:")
    
    # 1. Retention ratio
    retention_ratio = len(retained) / len(original_set) if original_set else 0
    print(f"   Direct retention: {retention_ratio*100:.1f}%")
    
    # 2. Introduction ratio
    introduction_ratio = len(new_cuis) / len(reduced_set) if reduced_set else 0
    print(f"   New CUI ratio: {introduction_ratio*100:.1f}%")
    
    # 3. Estimate coverage (assuming new CUIs are parents)
    estimated_coverage = (len(retained) + len(new_cuis)) / len(original_set) if original_set else 0
    print(f"   Estimated coverage: {min(estimated_coverage*100, 100):.1f}%")
    
    # Warning flags
    print(f"\nâš ï¸ WARNING FLAGS:")
    warnings = []
    
    if introduction_ratio > 0.5:
        warnings.append("High ratio of new CUIs - verify hierarchy correctness")
    
    if retention_ratio < 0.1 and introduction_ratio < 0.3:
        warnings.append("Very low retention with few new parents - possible information loss")
    
    if len(reduced_set) > len(original_set) * 0.5:
        warnings.append("Reduction less than 50% - may need more aggressive parameters")
    
    if len(new_cuis) == 0:
        warnings.append("No hierarchical rollup detected - only filtering occurred")
    
    if warnings:
        for warning in warnings:
            print(f"   âš ï¸ {warning}")
    else:
        print("   âœ… No warnings")
    
    # Sample analysis
    print(f"\nðŸ” SAMPLE ANALYSIS:")
    print(f"   Sample retained CUIs: {list(retained)[:5]}")
    print(f"   Sample new CUIs (likely parents): {list(new_cuis)[:5]}")
    print(f"   Sample removed CUIs: {list(removed)[:5]}")
    
    # Return metrics
    metrics = {
        'original_count': len(original_set),
        'reduced_count': len(reduced_set),
        'reduction_percentage': (1 - len(reduced_set)/len(original_set))*100 if original_set else 0,
        'retained_count': len(retained),
        'new_cui_count': len(new_cuis),
        'removed_count': len(removed),
        'retention_ratio': retention_ratio,
        'introduction_ratio': introduction_ratio,
        'estimated_coverage': estimated_coverage,
        'warnings': warnings
    }
    
    return metrics


def validate_with_known_relationships(
    original_cuis: List[str], 
    reduced_cuis: List[str],
    known_parent_child_pairs: List[Tuple[str, str]] = None
) -> Dict:
    """
    Validate using known parent-child relationships
    
    Args:
        original_cuis: Original CUI list
        reduced_cuis: Reduced CUI list
        known_parent_child_pairs: List of (parent, child) tuples
    """
    if not known_parent_child_pairs:
        # Example known relationships for brain tumor concepts
        known_parent_child_pairs = [
            ('C0006118', 'C0006142'),  # Brain Neoplasms -> Brain Tumor
            ('C0027651', 'C0006118'),  # Neoplasms -> Brain Neoplasms
            # Add your known relationships here
        ]
    
    original_set = set(original_cuis)
    reduced_set = set(reduced_cuis)
    
    correct_rollups = 0
    total_possible = 0
    
    for parent, child in known_parent_child_pairs:
        if child in original_set:
            total_possible += 1
            if parent in reduced_set and child not in reduced_set:
                correct_rollups += 1
    
    validity_score = correct_rollups / total_possible if total_possible else 0
    
    print(f"\nðŸŒ³ HIERARCHY VALIDATION:")
    print(f"   Known relationships tested: {total_possible}")
    print(f"   Correct rollups: {correct_rollups}")
    print(f"   Validity score: {validity_score*100:.1f}%")
    
    return {
        'hierarchy_validity_score': validity_score,
        'correct_rollups': correct_rollups,
        'total_tested': total_possible
    }


def analyze_reduction_patterns(reductions: List[Dict]) -> None:
    """
    Analyze patterns across multiple reductions
    
    Args:
        reductions: List of reduction results from quick_validate
    """
    print("\n" + "="*60)
    print("REDUCTION PATTERN ANALYSIS")
    print("="*60)
    
    # Aggregate statistics
    avg_reduction = np.mean([r['reduction_percentage'] for r in reductions])
    std_reduction = np.std([r['reduction_percentage'] for r in reductions])
    avg_retention = np.mean([r['retention_ratio'] for r in reductions])
    avg_introduction = np.mean([r['introduction_ratio'] for r in reductions])
    
    print(f"\nðŸ“ˆ AGGREGATE STATISTICS ({len(reductions)} samples):")
    print(f"   Average reduction: {avg_reduction:.1f}% (Â±{std_reduction:.1f}%)")
    print(f"   Average retention: {avg_retention*100:.1f}%")
    print(f"   Average new CUI ratio: {avg_introduction*100:.1f}%")
    
    # Quality distribution
    quality_scores = []
    for r in reductions:
        # Simple quality score based on reduction and coverage
        score = (r['reduction_percentage']/100 * 0.5 + 
                r['estimated_coverage'] * 0.5)
        quality_scores.append(score)
    
    print(f"\nâ­ QUALITY DISTRIBUTION:")
    print(f"   Excellent (>0.85): {sum(1 for s in quality_scores if s > 0.85)}")
    print(f"   Good (0.70-0.85): {sum(1 for s in quality_scores if 0.7 <= s <= 0.85)}")
    print(f"   Fair (0.50-0.70): {sum(1 for s in quality_scores if 0.5 <= s < 0.7)}")
    print(f"   Poor (<0.50): {sum(1 for s in quality_scores if s < 0.5)}")
    
    # Common warnings
    all_warnings = []
    for r in reductions:
        all_warnings.extend(r.get('warnings', []))
    
    if all_warnings:
        warning_counts = Counter(all_warnings)
        print(f"\nâš ï¸ COMMON WARNINGS:")
        for warning, count in warning_counts.most_common(3):
            print(f"   {warning}: {count} occurrences")


def create_test_cases() -> List[Dict]:
    """
    Create test cases for validation
    """
    return [
        {
            'text': 'brain tumor',
            'description': 'Simple oncology case'
        },
        {
            'text': 'History of Type 2 Diabetes Mellitus and hypertension',
            'description': 'Multiple conditions'
        },
        {
            'text': 'Patient presents with chest pain and shortness of breath',
            'description': 'Symptoms presentation'
        },
        {
            'text': 'Prescribed metformin 500mg twice daily for glucose control',
            'description': 'Medication and dosage'
        },
        {
            'text': 'MRI shows 2cm mass in left frontal lobe with surrounding edema',
            'description': 'Imaging findings'
        }
    ]


def generate_validation_report(
    original_cuis: List[str],
    reduced_cuis: List[str],
    text: str,
    output_file: str = "validation_report.txt"
) -> None:
    """
    Generate a detailed validation report
    """
    with open(output_file, 'w') as f:
        f.write("="*80 + "\n")
        f.write("CUI REDUCTION VALIDATION REPORT\n")
        f.write("="*80 + "\n\n")
        
        f.write(f"Input Text: {text}\n")
        f.write(f"Original CUIs: {len(original_cuis):,}\n")
        f.write(f"Reduced CUIs: {len(reduced_cuis):,}\n")
        f.write(f"Reduction: {(1 - len(reduced_cuis)/len(original_cuis))*100:.1f}%\n\n")
        
        # Perform validation
        metrics = quick_validate(original_cuis, reduced_cuis, text)
        
        f.write("VALIDATION METRICS:\n")
        f.write("-"*40 + "\n")
        for key, value in metrics.items():
            if key != 'warnings':
                f.write(f"{key}: {value}\n")
        
        f.write("\nWARNINGS:\n")
        f.write("-"*40 + "\n")
        for warning in metrics.get('warnings', []):
            f.write(f"- {warning}\n")
        
        f.write("\nRECOMMENDATIONS:\n")
        f.write("-"*40 + "\n")
        
        if metrics['reduction_percentage'] < 70:
            f.write("- Consider increasing reduction aggressiveness\n")
            f.write("- Try lower IC percentile (e.g., 40 instead of 50)\n")
            f.write("- Enable semantic clustering if not already enabled\n")
        
        if metrics['introduction_ratio'] > 0.6:
            f.write("- High parent introduction rate detected\n")
            f.write("- Verify UMLS hierarchy relationships are correct\n")
            f.write("- Consider adjusting hierarchy traversal depth\n")
        
        if metrics['retention_ratio'] < 0.1:
            f.write("- Very low direct retention\n")
            f.write("- Verify that important specific concepts aren't lost\n")
            f.write("- Consider manual review of critical CUIs\n")
        
        f.write("\n" + "="*80 + "\n")
        f.write("Report generated successfully\n")
    
    print(f"\nâœ… Validation report saved to: {output_file}")


# Example usage
if __name__ == "__main__":
    # Example with your brain tumor case
    print("EXAMPLE: Brain Tumor CUI Reduction Validation")
    
    # Simulated data (replace with your actual CUIs)
    original_cuis = [f"C{str(i).zfill(7)}" for i in range(10000)]  # 10,000 CUIs
    reduced_cuis = [f"C{str(i).zfill(7)}" for i in range(0, 10000, 3)]  # ~3,000 CUIs
    # Add some parent CUIs
    reduced_cuis.extend([f"P{str(i).zfill(7)}" for i in range(100)])
    
    # Run validation
    metrics = quick_validate(original_cuis, reduced_cuis, "brain tumor")
    
    # Save results
    with open('validation_metrics.json', 'w') as f:
        json.dump(metrics, f, indent=2)
    
    print(f"\nðŸ’¾ Metrics saved to validation_metrics.json")
    
    # Generate report
    generate_validation_report(
        original_cuis, 
        reduced_cuis, 
        "brain tumor",
        "brain_tumor_validation.txt"
    )
