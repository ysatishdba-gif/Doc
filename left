"""
RIGHT HAND SIDE: Document Topic CUI Extraction
==============================================
INPUT:  Multiple document topics/descriptions
OUTPUT: Topic CUI set + Graph + Embeddings

Simpler than LHS - just extraction, filtering, graph building
(No heavy reduction needed for document topics)
"""

import pickle
import subprocess
import logging
import time
import threading
from typing import List, Dict, Set
from collections import defaultdict
import numpy as np
from google.cloud import bigquery
import requests
from requests.adapters import HTTPAdapter, Retry
import networkx as nx

# =============================================================================
# CONFIGURATION
# =============================================================================

CONFIG = {
    'project_id': 'your-gcp-project',
    'dataset_id': 'umls_2024',
    'cui_embeddings_table': 'cui_embeddings_v1',
    'api_url': 'https://your-api.run.app/extract',
    'network_pkl': '/home/jupyter/CUIreduction/networkx_cui_context_v1_1_0.pkl',
    'output_graph': 'rhs_topic_graph.pkl',
    'output_embeddings': 'rhs_embeddings.pkl',
}

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# =============================================================================
# GCP TOKEN PROVIDER
# =============================================================================

class GCPTokenProvider:
    _lock = threading.Lock()
    _token = None
    _expiry = 0

    @classmethod
    def get_headers(cls, force: bool = False) -> Dict[str, str]:
        with cls._lock:
            now = time.time()
            if not force and cls._token and now < cls._expiry:
                return cls._token
            
            proc = subprocess.run(
                ["gcloud", "auth", "print-identity-token"],
                stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, timeout=10
            )
            if proc.returncode != 0:
                raise RuntimeError(proc.stderr)
            
            token = proc.stdout.strip()
            cls._token = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}
            cls._expiry = now + 3300
            return cls._token

# =============================================================================
# CUI API CLIENT
# =============================================================================

class CUIAPIClient:
    def __init__(self, api_url: str, timeout: int = 60, top_k: int = 3):
        self.api_url = api_url.rstrip('/')
        self.timeout = timeout
        self.top_k = top_k
        self.session = requests.Session()
        retry = Retry(total=3, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504])
        self.session.mount("http://", HTTPAdapter(max_retries=retry))
        self.session.mount("https://", HTTPAdapter(max_retries=retry))

    def extract_cuis(self, texts: List[str]) -> Set[str]:
        if not texts:
            return set()
        payload = {"query_texts": texts, "top_k": self.top_k}
        headers = GCPTokenProvider.get_headers()
        
        try:
            response = self.session.post(self.api_url, json=payload, headers=headers, timeout=self.timeout)
            if response.status_code == 401:
                GCPTokenProvider.get_headers(force=True)
                response = self.session.post(self.api_url, json=payload, headers=GCPTokenProvider.get_headers(), timeout=self.timeout)
            response.raise_for_status()
            
            data = response.json()
            all_cuis = set()
            for text in texts:
                cuis = data.get(text, [])
                if isinstance(cuis, list):
                    all_cuis.update(str(c) for c in cuis if c)
            return all_cuis
        except Exception as e:
            logger.error(f"API call failed: {e}")
            return set()

# =============================================================================
# HELPER FUNCTIONS
# =============================================================================

def filter_cuis(cuis: Set[str], project_id: str, dataset_id: str) -> List[str]:
    """Filter CUIs to retain only ICD, SNOMED, LOINC"""
    if not cuis:
        return []
    
    client = bigquery.Client(project=project_id)
    query = f"""
    SELECT DISTINCT CUI
    FROM `{project_id}.{dataset_id}.MRCONSO`
    WHERE CUI IN UNNEST(@cuis)
      AND SAB IN ('CCSR_ICD10CM','CCSR_ICD10PCS','DMDICD10','ICD10','ICD10AE','ICD10AM',
                  'ICD10CM','ICD10PCS','ICD9CM','SNOMEDCT_US','LOINC')
    """
    job_config = bigquery.QueryJobConfig(
        query_parameters=[bigquery.ArrayQueryParameter("cuis", "STRING", list(cuis))]
    )
    df = client.query(query, job_config=job_config).result(timeout=60).to_dataframe()
    return df['CUI'].tolist()

# =============================================================================
# MAIN RIGHT HAND SIDE PIPELINE
# =============================================================================

class RightHandSide:
    """Complete RHS pipeline: Document topics â†’ Topic CUIs + Graph + Embeddings"""
    
    def __init__(self, config: Dict):
        self.config = config
        
        # Load UMLS graph
        logger.info(f"Loading UMLS graph from {config['network_pkl']}")
        with open(config['network_pkl'], 'rb') as f:
            self.umls_graph = pickle.load(f)
        logger.info(f"Loaded graph: {self.umls_graph.number_of_nodes():,} nodes")
        
        # Initialize components
        self.api_client = CUIAPIClient(config['api_url'])
        self.bq_client = bigquery.Client(project=config['project_id'])
    
    def process(self, document_topics: List[str]) -> Dict:
        """
        Main processing function
        
        Args:
            document_topics: List of document topics/descriptions
                Example: [
                    "patient weight measured in grams",
                    "gram stain laboratory test",
                    "medication dosage in grams"
                ]
        
        Returns:
            dict with keys:
                - topic_cuis: List[str]
                - topic_graph: nx.DiGraph
                - embeddings: Dict[str, np.ndarray]
                - cui_to_topics: Dict[str, List[str]] - which CUIs came from which topics
        """
        print("\n" + "="*80)
        print("RIGHT HAND SIDE: DOCUMENT TOPIC CUI EXTRACTION")
        print("="*80)
        print(f"Processing {len(document_topics)} document topics")
        print("-"*80)
        
        # Step 1: Extract CUIs from all topics
        print("\n[1/4] Extracting CUIs from topics...")
        all_cuis = set()
        cui_to_topics = defaultdict(list)
        
        for i, topic in enumerate(document_topics, 1):
            topic_cuis = self.api_client.extract_cuis([topic])
            all_cuis.update(topic_cuis)
            for cui in topic_cuis:
                cui_to_topics[cui].append(topic)
            print(f"      Topic {i:2d}: {len(topic_cuis):3d} CUIs - '{topic[:60]}{'...' if len(topic) > 60 else ''}'")
        
        print(f"\n      Total unique CUIs: {len(all_cuis)}")
        
        # Step 2: Filter vocabularies
        print("[2/4] Filtering to allowed vocabularies (ICD, SNOMED, LOINC)...")
        filtered_cuis = filter_cuis(all_cuis, self.config['project_id'], self.config['dataset_id'])
        print(f"      After filter: {len(filtered_cuis)} CUIs")
        
        # Step 3: Keep only valid CUIs in UMLS graph
        valid_cuis = [cui for cui in filtered_cuis if self.umls_graph.has_node(cui)]
        print(f"      Valid CUIs (in UMLS graph): {len(valid_cuis)}")
        
        # Step 4: Build topic graph
        print("[3/4] Building topic graph with edges...")
        topic_graph = self._build_graph_with_parents(valid_cuis)
        print(f"      Nodes: {topic_graph.number_of_nodes():,}")
        print(f"      Edges: {topic_graph.number_of_edges():,}")
        
        # Step 5: Fetch embeddings
        print("[4/4] Fetching embeddings...")
        embeddings = self._fetch_embeddings(valid_cuis)
        print(f"      Embeddings: {len(embeddings)}")
        
        # Save outputs
        with open(self.config['output_graph'], 'wb') as f:
            pickle.dump(topic_graph, f)
        with open(self.config['output_embeddings'], 'wb') as f:
            pickle.dump(embeddings, f)
        
        print("\nâœ“ RIGHT HAND SIDE COMPLETE")
        print(f"  Saved graph: {self.config['output_graph']}")
        print(f"  Saved embeddings: {self.config['output_embeddings']}")
        print("="*80 + "\n")
        
        return {
            'topic_cuis': valid_cuis,
            'topic_graph': topic_graph,
            'embeddings': embeddings,
            'cui_to_topics': dict(cui_to_topics)
        }
    
    def _build_graph_with_parents(self, cuis: List[str]) -> nx.DiGraph:
        """Build graph including parent relationships"""
        G = nx.DiGraph()
        G.add_nodes_from(cuis)
        
        for cui in cuis:
            if self.umls_graph.has_node(cui):
                for parent in self.umls_graph.predecessors(cui):
                    G.add_node(parent)
                    G.add_edge(cui, parent)
        
        return G
    
    def _fetch_embeddings(self, cuis: List[str]) -> Dict[str, np.ndarray]:
        """Fetch embeddings from BigQuery"""
        if not cuis:
            return {}
        
        query = f"""
        SELECT CUI AS cui, embedding
        FROM `{self.config['project_id']}.{self.config['dataset_id']}.{self.config['cui_embeddings_table']}`
        WHERE CUI IN UNNEST(@cuis)
        """
        job_config = bigquery.QueryJobConfig(
            query_parameters=[bigquery.ArrayQueryParameter("cuis", "STRING", cuis)]
        )
        df = self.bq_client.query(query, job_config=job_config).result(timeout=60).to_dataframe()
        
        embeddings = {}
        for _, row in df.iterrows():
            if row["embedding"] is not None:
                embeddings[row["cui"]] = np.asarray(row["embedding"], dtype=np.float32)
        
        return embeddings

# =============================================================================
# USAGE
# =============================================================================

if __name__ == "__main__":
    # Initialize RHS pipeline
    rhs = RightHandSide(CONFIG)
    
    # Example document topics
    document_topics = [
        "patient weight measured in grams",
        "gram stain laboratory test result",
        "medication dosage in grams per day",
        "tumor mass measurement in grams",
        "dietary fiber intake grams daily",
        "hemoglobin level grams per deciliter",
        "protein content grams per serving"
    ]
    
    # Process topics
    result = rhs.process(document_topics)
    
    # Display results
    print("\nðŸ“Š RESULTS:")
    print(f"   Topic CUIs: {len(result['topic_cuis'])}")
    print(f"   Graph nodes: {result['topic_graph'].number_of_nodes()}")
    print(f"   Embeddings: {len(result['embeddings'])}")
    
    print(f"\n   Sample CUIs and their source topics:")
    for cui, topics in list(result['cui_to_topics'].items())[:5]:
        print(f"     {cui}: {topics[0][:60]}...")
