# %% Retention v6: alignment-first, no tricks

from google import genai
from collections import defaultdict

client = genai.Client(vertexai=True, project=PROJECT_ID, location="us-central1")

def compute_retention(text, result, embs, ic_precomputed, metadata_cache):
    """
    Information Retention Scoring

    Measures how much of the user's narrative each CUI retains.
    
    Primary signal: cosine(text_embedding, cui_embedding) in the same
    3072 gemini-embedding-001 space. This captures specificity, qualifiers,
    laterality, and semantic alignment in one number — no token matching,
    no stemming, no hardcoded weights.

    Secondary: explains_count from audit trail (tiebreaker only).

    Cost: 1 embedding call (~100ms, ~$0.0001). Rest is in memory.
    """

    surviving = result.all_reduced_cuis
    if not surviving:
        return [], {}

    # one embedding call
    response = client.models.embed_content(
        model="gemini-embedding-001",
        contents=text,
    )
    text_vec = np.array(response.embeddings[0].values, dtype=np.float32)
    text_vec = text_vec / (np.linalg.norm(text_vec) + 1e-10)

    # alignment: cosine(text, cui) — this IS the retention score
    alignments = {}
    for cui in surviving:
        if cui in embs:
            alignments[cui] = float(np.dot(text_vec, embs[cui]))
        else:
            alignments[cui] = 0.0

    # explains map from audit trail
    explains = defaultdict(set)
    for entry in result.audit_trail:
        if entry.kept_cui and entry.removed_cui:
            explains[entry.kept_cui].add(entry.removed_cui)

    # build output
    retention = {}
    for cui in surviving:
        m = metadata_cache.get(cui)
        if not m:
            continue
        retention[cui] = {
            "alignment": round(alignments.get(cui, 0.0), 4),
            "explains_count": len(explains.get(cui, set())),
            "term": m.preferred_term,
            "semantic_types": m.semantic_types,
            "explains_cuis": list(explains.get(cui, set())),
        }

    # sort: alignment first, explains_count as tiebreaker
    sorted_cuis = sorted(
        retention.keys(),
        key=lambda c: (retention[c]["alignment"], retention[c]["explains_count"]),
        reverse=True)

    return sorted_cuis, retention


# %% Run
metadata_cache = {c: system.fetcher._cache.get(c)
                  for c in result.all_reduced_cuis
                  if system.fetcher._cache.get(c)}

sorted_cuis, retention = compute_retention(
    text, result, embs, ic_precomputed, metadata_cache)

# show alignment distribution
all_align = [retention[c]["alignment"] for c in sorted_cuis]
print(f"Alignment range: {min(all_align):.3f} to {max(all_align):.3f}")
print(f"Mean: {np.mean(all_align):.3f}, Std: {np.std(all_align):.3f}")

print(f"\nTop 30 CUIs by narrative retention:")
for c in sorted_cuis[:30]:
    r = retention[c]
    stys = ", ".join(r["semantic_types"][:2]) if r["semantic_types"] else "?"
    line = (f"  {c} | align={r['alignment']} "
            f"| [{stys}] {r['term']}")
    if r["explains_count"] > 0:
        line += f" | explains {r['explains_count']}"
    print(line)

print(f"\nBottom 10 (least aligned):")
for c in sorted_cuis[-10:]:
    r = retention[c]
    print(f"  {c} | align={r['alignment']} | {r['term']}")
