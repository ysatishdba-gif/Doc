"""
CUI Reduction System
====================
Reduces 20K+ extracted CUIs to two actionable tiers:

  Search CUIs — mid-level concepts for document retrieval
  Topic CUIs  — broad cluster-head concepts for topic labels

Scoring uses two signals:
  1. Relevance  — cosine(text embedding, CUI embedding)
     "Is this concept about what the clinical text says?"
  2. Specificity — IC ratio within this CUI set
     "Among relevant concepts, which is most precise?"

Weights derived per-request from score variance (no BQ config query).
Hierarchy edges handle deduplication — children retain ancestors.
Every CUI gets a human-readable explanation of its fate.

No tokenization. No stopwords. No text matching.
The extraction API bridges text→CUI. Embeddings bridge CUI→relevance.
UMLS hierarchy bridges CUI→specificity. That's the full signal chain.

Stages:
  1. Metadata fetch (batched BQ)
  2. SAB filter (keep target vocabularies)
  3. Embed clinical text (Gemini embedding-001)
  4. Score each CUI — relevance + specificity, variance-weighted
  5. Remove noise (mean - std of score distribution)
  6. Hierarchy retention (children retain ancestors)
  7. Tier classification (depth from leaf in hierarchy)

Requirements:
  pip install google-cloud-bigquery google-genai networkx numpy requests
"""

import math
import time
import threading
import logging
from typing import List, Dict, Optional, Set, Tuple
from dataclasses import dataclass, field
from collections import defaultdict, deque, OrderedDict
from enum import Enum
from functools import wraps

import numpy as np
import networkx as nx
import requests
import subprocess
from google.cloud import bigquery

# ========================= LOGGING =========================

_logger = logging.getLogger("cui_reduction")
if not _logger.handlers:
    _handler = logging.StreamHandler()
    _handler.setFormatter(logging.Formatter(
        "%(asctime)s [%(levelname)s] %(message)s"))
    _logger.addHandler(_handler)
    _logger.setLevel(logging.INFO)
    _logger.propagate = False


def log(msg: str, level: str = "INFO"):
    getattr(_logger, level.lower(), _logger.info)(msg)


# ========================= TIMING =========================

_TIMING_BUFFER_SIZE = 1000
_timings: Dict[str, deque] = defaultdict(
    lambda: deque(maxlen=_TIMING_BUFFER_SIZE))
_timing_lock = threading.Lock()


def timed(name: str):
    def dec(fn):
        @wraps(fn)
        def wrapper(*a, **kw):
            t0 = time.perf_counter()
            try:
                return fn(*a, **kw)
            finally:
                with _timing_lock:
                    _timings[name].append(
                        (time.perf_counter() - t0) * 1000)
        return wrapper
    return dec


def get_timings() -> Dict[str, Dict[str, float]]:
    with _timing_lock:
        out = {}
        for k, v in _timings.items():
            if v:
                vals = list(v)
                out[k] = {
                    "count": len(vals),
                    "mean_ms": float(np.mean(vals)),
                    "p50_ms": float(np.median(vals)),
                    "p99_ms": float(np.percentile(vals, 99)),
                    "max_ms": float(np.max(vals)),
                }
        return out


# ========================= CACHE =========================

_CACHE_HARD_CAP = 200_000
_cache_total = 0
_cache_total_lock = threading.Lock()
_CACHE_GLOBAL_CAP = 1_000_000


class Cache:
    """Thread-safe LRU with hard memory caps."""

    def __init__(self, max_size: int):
        global _cache_total
        self._d: OrderedDict = OrderedDict()
        self._lock = threading.RLock()
        capped = max(1, min(max_size, _CACHE_HARD_CAP))
        with _cache_total_lock:
            remaining = max(1, _CACHE_GLOBAL_CAP - _cache_total)
            self._max = min(capped, remaining)
            _cache_total += self._max

    def get(self, key):
        with self._lock:
            if key in self._d:
                self._d.move_to_end(key)
                return self._d[key]
            return None

    def put(self, key, val):
        with self._lock:
            if key in self._d:
                self._d.move_to_end(key)
            self._d[key] = val
            while len(self._d) > self._max:
                self._d.popitem(last=False)


# ========================= DATA MODELS =========================

class UsageContext(Enum):
    QUERY = "query"
    DOCUMENT = "document"


class Tier(Enum):
    SEARCH = "search"
    TOPIC = "topic"


@dataclass
class CUIMetadata:
    cui: str
    preferred_term: str
    semantic_types: List[str]
    ic_score: float
    source_vocabs: List[str] = field(default_factory=list)


@dataclass
class CUIAssessment:
    """Full assessment with explainability."""
    cui: str
    preferred_term: str
    confidence: float           # combined score, 0-1
    relevance: float            # text↔CUI cosine, 0-1
    specificity: float          # IC / max_IC, 0-1
    tier: Tier = Tier.SEARCH
    depth_from_leaf: int = 0
    retained_cuis: List[str] = field(default_factory=list)
    explanation: str = ""
    ranking: int = 0


@dataclass
class ReductionResult:
    context_string: str
    usage_context: UsageContext
    search_cuis: List[str]
    topic_cuis: List[str]
    all_surviving: List[str]
    assessments: Dict[str, CUIAssessment]
    retention_map: Dict[str, List[str]]
    removed: Dict[str, str]
    input_count: int
    processing_time_ms: float
    stage_counts: Dict[str, int] = field(default_factory=dict)
    weights: Dict[str, float] = field(default_factory=dict)


# ========================= HIERARCHY CLIENT =========================

class HierarchyClient:
    """Navigates UMLS hierarchy with deque BFS and depth caps."""

    def __init__(self, network: nx.DiGraph,
                 ic_scores: Optional[Dict[str, float]] = None,
                 cache_size: int = 1):
        self.network = network
        self.ic_scores = ic_scores or {}
        self._ic_cache = Cache(cache_size)
        self._parent_cache = Cache(cache_size)
        self._children_cache = Cache(cache_size)

        n = network.number_of_nodes()
        e = network.number_of_edges()
        avg_deg = (e / n) if n > 0 else 1
        self._max_depth = max(
            int(np.log(max(n, 1)) / np.log(max(avg_deg, 2))), 3)
        log(f"Hierarchy: {n} nodes, {e} edges, max_depth={self._max_depth}")

    def get_ic(self, cui: str) -> float:
        cached = self._ic_cache.get(cui)
        if cached is not None:
            return cached
        if cui in self.ic_scores:
            ic = float(self.ic_scores[cui])
        else:
            ic = float(np.log1p(self._depth_to_root(cui)))
        if not np.isfinite(ic):
            ic = 0.0
        self._ic_cache.put(cui, ic)
        return ic

    def _depth_to_root(self, cui: str) -> int:
        if not self.network.has_node(cui):
            return 0
        visited, q, depth = {cui}, deque([cui]), 0
        while q and depth < self._max_depth:
            nxt = []
            for _ in range(len(q)):
                for p in self.get_parents(q.popleft()):
                    if p not in visited:
                        visited.add(p)
                        nxt.append(p)
            if not nxt:
                break
            q.extend(nxt)
            depth += 1
        return depth

    def get_parents(self, cui: str) -> List[str]:
        cached = self._parent_cache.get(cui)
        if cached is not None:
            return cached
        parents = (list(self.network.predecessors(cui))
                   if self.network.has_node(cui) else [])
        self._parent_cache.put(cui, parents)
        return parents

    def get_children(self, cui: str) -> List[str]:
        cached = self._children_cache.get(cui)
        if cached is not None:
            return cached
        children = (list(self.network.successors(cui))
                    if self.network.has_node(cui) else [])
        self._children_cache.put(cui, children)
        return children

    def depth_to_nearest_leaf(self, cui: str, cui_set: Set[str]) -> int:
        """Hops down to most specific descendant in cui_set. 0 = leaf."""
        if not self.network.has_node(cui):
            return 0
        visited = {cui}
        q: deque = deque([(cui, 0)])
        max_d = 0
        while q:
            node, d = q.popleft()
            if d >= self._max_depth:
                continue
            for child in self.get_children(node):
                if child not in visited:
                    visited.add(child)
                    if child in cui_set:
                        max_d = max(max_d, d + 1)
                    q.append((child, d + 1))
        return max_d

    def find_ancestors_in_set(self, cui: str,
                              cui_set: Set[str]) -> List[str]:
        """BFS up — find all ancestors of cui that are in cui_set."""
        found = []
        visited = {cui}
        q = deque()
        for p in self.get_parents(cui):
            if p not in visited:
                visited.add(p)
                q.append((p, 1))
        while q:
            node, depth = q.popleft()
            if depth > self._max_depth:
                continue
            if node in cui_set:
                found.append(node)
            for p in self.get_parents(node):
                if p not in visited:
                    visited.add(p)
                    q.append((p, depth + 1))
        return found


# ========================= TEXT EMBEDDER =========================

class TextEmbedder:
    """
    Embeds clinical text using Gemini embedding-001 via Vertex AI.
    - 3072 dimensions (matches pre-computed CUI embeddings)
    - Pre-normalized by Gemini API (cosine = dot product)
    - task_type configurable to match how CUIs were embedded
    """

    def __init__(self, project_id: str, location: str = "us-central1",
                 task_type: str = "SEMANTIC_SIMILARITY"):
        from google import genai
        self._client = genai.Client(
            vertexai=True,
            project=project_id,
            location=location,
        )
        self._model = "gemini-embedding-001"
        self._task_type = task_type
        self._expected_dim = 3072

    @timed("text_embedding")
    def embed(self, text: str,
              cui_embeddings: Optional[Dict[str, np.ndarray]] = None
              ) -> Optional[np.ndarray]:
        """Embed clinical text. Optionally validates dimension match
        against CUI embeddings."""
        try:
            from google.genai import types
            resp = self._client.models.embed_content(
                model=self._model,
                contents=text,
                config=types.EmbedContentConfig(
                    task_type=self._task_type,
                    output_dimensionality=self._expected_dim,
                ),
            )
            emb = np.array(resp.embeddings[0].values, dtype=np.float64)

            if emb.ndim != 1 or not np.all(np.isfinite(emb)):
                log("Text embedding returned invalid array", "WARNING")
                return None

            # Dimension validation against CUI embeddings
            if cui_embeddings:
                sample_cui_emb = next(iter(cui_embeddings.values()))
                if emb.shape[0] != sample_cui_emb.shape[0]:
                    log(f"DIMENSION MISMATCH: text={emb.shape[0]}, "
                        f"CUI={sample_cui_emb.shape[0]}. "
                        f"Cosine comparisons will be invalid!", "ERROR")
                    return None

            log(f"  Text embedded: dim={emb.shape[0]}, "
                f"norm={np.linalg.norm(emb):.4f}")
            return emb

        except Exception as e:
            log(f"Text embedding failed: {e}", "ERROR")
            return None


# ========================= METADATA FETCHER =========================

_BQ_BATCH_SIZE = 5000


class MetadataFetcher:
    """Batched BQ fetch for CUI metadata. No tokenization."""

    def __init__(self, bq: bigquery.Client, pid: str, did: str,
                 hierarchy: HierarchyClient, cache_size: int):
        self.bq = bq
        self.pid = pid
        self.did = did
        self.hierarchy = hierarchy
        self._cache = Cache(cache_size)

    @timed("metadata_fetch")
    def fetch(self, cuis: List[str]) -> Dict[str, CUIMetadata]:
        result, missing = {}, []
        for c in cuis:
            cached = self._cache.get(c)
            if cached:
                result[c] = cached
            else:
                missing.append(c)

        if not missing:
            return result

        for i in range(0, len(missing), _BQ_BATCH_SIZE):
            batch = missing[i:i + _BQ_BATCH_SIZE]
            query = f"""
            SELECT c.CUI AS cui,
              ANY_VALUE(CASE WHEN c.ISPREF = 'Y' THEN c.STR END) AS pref_term,
              ARRAY_AGG(DISTINCT s.TUI IGNORE NULLS) AS tuis,
              ARRAY_AGG(DISTINCT c.SAB IGNORE NULLS) AS sabs
            FROM `{self.pid}.{self.did}.MRCONSO` c
            LEFT JOIN `{self.pid}.{self.did}.MRSTY` s ON c.CUI = s.CUI
            WHERE c.CUI IN UNNEST(@cuis) AND c.LAT = 'ENG'
            GROUP BY c.CUI
            """
            jc = bigquery.QueryJobConfig(query_parameters=[
                bigquery.ArrayQueryParameter("cuis", "STRING", batch)
            ])
            try:
                for row in self.bq.query(
                        query, job_config=jc, timeout=300).result():
                    meta = CUIMetadata(
                        cui=row.cui,
                        preferred_term=row.pref_term or "",
                        semantic_types=row.tuis or [],
                        ic_score=self.hierarchy.get_ic(row.cui),
                        source_vocabs=row.sabs or [],
                    )
                    self._cache.put(row.cui, meta)
                    result[row.cui] = meta
            except Exception as e:
                log(f"Metadata fetch error (batch {i}): {e}", "ERROR")

        fetched = len(result) - (len(cuis) - len(missing))
        if fetched < len(missing):
            log(f"  Metadata partial: got {fetched}/{len(missing)}",
                "WARNING")
        return result


# ========================= SAB FILTER =========================

class SABFilter:
    def __init__(self, allowed_sabs: Set[str]):
        self.allowed = allowed_sabs

    @timed("sab_filter")
    def run(self, cuis: List[str],
            metadata: Dict[str, CUIMetadata]
            ) -> Tuple[List[str], Dict[str, str]]:
        kept, removed = [], {}
        for cui in cuis:
            meta = metadata.get(cui)
            if not meta:
                removed[cui] = "no_metadata"
            elif not (set(meta.source_vocabs) & self.allowed):
                sabs = meta.source_vocabs
                removed[cui] = f"sab_not_allowed (has {sabs})"
            else:
                kept.append(cui)
        return kept, removed


# ========================= COSINE UTILITY =========================

def safe_cosine(a: np.ndarray, b: np.ndarray) -> float:
    """Cosine similarity with zero/NaN guard.
    Gemini embedding-001 outputs are pre-normalized (L2 norm ≈ 1.0),
    so cosine ≈ dot product. We still compute full cosine for safety.
    Returns [0, 1] range by shifting from [-1, 1]."""
    na, nb = np.linalg.norm(a), np.linalg.norm(b)
    if na == 0 or nb == 0:
        return 0.0
    raw = float(np.dot(a, b) / (na * nb))
    # Shift [-1, 1] → [0, 1] so scores are always non-negative
    return max(0.0, min(1.0, (raw + 1.0) / 2.0))


# ========================= SCORER =========================

class RelevanceSpecificityScorer:
    """
    Two-component scoring:
      1. Relevance — cosine(text_embedding, cui_embedding)
      2. Specificity — IC / max_IC in this set

    Weights derived per-request from score variance:
      Higher variance = more discriminative = higher weight.
      This is the same principle as TF-IDF — features that
      spread out carry more information.
    """

    @staticmethod
    @timed("scoring")
    def score(
        cuis: List[str],
        metadata: Dict[str, CUIMetadata],
        text_embedding: Optional[np.ndarray],
        cui_embeddings: Dict[str, np.ndarray],
    ) -> Tuple[Dict[str, CUIAssessment], Dict[str, float]]:
        """Returns (assessments, weights_used)."""

        # --- Compute raw scores ---

        # Max IC from THIS set for normalization
        ic_vals = [metadata[c].ic_score for c in cuis if c in metadata]
        max_ic = max(ic_vals) if ic_vals else 1.0
        if max_ic <= 0 or not np.isfinite(max_ic):
            max_ic = 1.0

        raw_relevance: Dict[str, float] = {}
        raw_specificity: Dict[str, float] = {}
        _MISSING = float("nan")

        for cui in cuis:
            meta = metadata.get(cui)
            if not meta:
                continue

            # Specificity: always computable from UMLS
            spec = meta.ic_score / max_ic
            raw_specificity[cui] = spec if np.isfinite(spec) else 0.0

            # Relevance: needs both embeddings
            if text_embedding is not None and cui in cui_embeddings:
                raw_relevance[cui] = safe_cosine(
                    text_embedding, cui_embeddings[cui])
            else:
                raw_relevance[cui] = _MISSING

        # --- Backfill missing relevance with median ---
        computed = [v for v in raw_relevance.values() if np.isfinite(v)]
        median_rel = float(np.median(computed)) if computed else 0.5
        for cui in raw_relevance:
            if not np.isfinite(raw_relevance[cui]):
                raw_relevance[cui] = median_rel

        # --- Derive weights from variance ---
        scored_cuis = [c for c in cuis if c in raw_relevance
                       and c in raw_specificity]
        if not scored_cuis:
            weights = {"relevance": 0.5, "specificity": 0.5}
        else:
            rel_vals = [raw_relevance[c] for c in scored_cuis]
            spec_vals = [raw_specificity[c] for c in scored_cuis]
            var_rel = float(np.std(rel_vals))
            var_spec = float(np.std(spec_vals))
            total_var = var_rel + var_spec
            if total_var > 1e-10:
                weights = {
                    "relevance": var_rel / total_var,
                    "specificity": var_spec / total_var,
                }
            else:
                weights = {"relevance": 0.5, "specificity": 0.5}

        # --- Combine into assessments ---
        assessments: Dict[str, CUIAssessment] = {}
        for cui in cuis:
            meta = metadata.get(cui)
            if not meta or cui not in raw_relevance:
                continue

            rel = raw_relevance[cui]
            spec = raw_specificity[cui]
            conf = (weights["relevance"] * rel
                    + weights["specificity"] * spec)

            assessments[cui] = CUIAssessment(
                cui=cui,
                preferred_term=meta.preferred_term,
                confidence=conf,
                relevance=rel,
                specificity=spec,
            )

        return assessments, weights


# ========================= NOISE REMOVAL =========================

class NoiseRemover:
    """
    Threshold = mean - std of score distribution.
    Guards: skip if < 3 CUIs or std ≈ 0.
    """

    @staticmethod
    @timed("noise_removal")
    def run(cuis: List[str],
            assessments: Dict[str, CUIAssessment]
            ) -> Tuple[List[str], Dict[str, str]]:

        if len(cuis) < 3:
            return cuis, {}

        scores = [assessments[c].confidence
                  for c in cuis
                  if c in assessments
                  and np.isfinite(assessments[c].confidence)]
        if not scores:
            return cuis, {}

        mean_s = float(np.mean(scores))
        std_s = float(np.std(scores))
        if std_s < 1e-10:
            return cuis, {}

        threshold = max(mean_s - std_s, 0.0)

        kept, removed = [], {}
        for cui in cuis:
            a = assessments.get(cui)
            if not a:
                removed[cui] = "no_assessment"
            elif not np.isfinite(a.confidence):
                removed[cui] = "non_finite_score"
            elif a.confidence < threshold:
                removed[cui] = (
                    f"noise (score={a.confidence:.3f} < "
                    f"threshold={threshold:.3f}, "
                    f"relevance={a.relevance:.2f}, "
                    f"specificity={a.specificity:.2f})")
            else:
                kept.append(cui)
        return kept, removed


# ========================= HIERARCHY RETENTION =========================

class HierarchyRetainer:
    """
    Removes redundant ancestors using hierarchy edges.
    A specific child retains (explains away) its less-specific ancestors.
    BFS up from each CUI finds all ancestors in the surviving set.

    This replaces both token-based deduplication and token-based
    retention mapping — the hierarchy IS the redundancy map.
    """

    def __init__(self, hierarchy: HierarchyClient):
        self.hierarchy = hierarchy

    @timed("hierarchy_retention")
    def run(
        self, cuis: List[str], metadata: Dict[str, CUIMetadata],
    ) -> Tuple[List[str], Dict[str, List[str]], Dict[str, str]]:
        """Returns (surviving, retention_map, removed)."""

        cui_set = set(cuis)
        # Track which ancestors are retained and by whom
        ancestor_retainers: Dict[str, Set[str]] = defaultdict(set)

        for cui in cuis:
            meta = metadata.get(cui)
            if not meta:
                continue

            # Find all ancestors of this CUI in the surviving set
            ancestors = self.hierarchy.find_ancestors_in_set(cui, cui_set)

            for anc in ancestors:
                anc_meta = metadata.get(anc)
                if anc_meta and meta.ic_score >= anc_meta.ic_score:
                    ancestor_retainers[anc].add(cui)

        # Build results
        to_remove = set(ancestor_retainers.keys())
        surviving = [c for c in cuis if c not in to_remove]
        surviving_set = set(surviving)

        # Retention map: surviving CUI → list of ancestors it retains
        retention_map: Dict[str, List[str]] = {c: [] for c in surviving}
        for anc, retainers in ancestor_retainers.items():
            for r in retainers:
                if r in surviving_set:
                    retention_map[r].append(anc)

        # Removed dict with explanation
        removed: Dict[str, str] = {}
        for anc, retainers in ancestor_retainers.items():
            # Pick highest-IC retainer for the explanation
            surviving_retainers = [r for r in retainers
                                   if r in surviving_set]
            if surviving_retainers:
                best = max(surviving_retainers,
                           key=lambda c: (metadata[c].ic_score
                                          if c in metadata else 0))
                b_meta = metadata.get(best)
                a_meta = metadata.get(anc)
                removed[anc] = (
                    f"redundant — retained by {best} "
                    f"'{b_meta.preferred_term if b_meta else '?'}' "
                    f"(IC {b_meta.ic_score:.1f if b_meta else 0} > "
                    f"{a_meta.ic_score:.1f if a_meta else 0})")
            else:
                removed[anc] = "redundant — retained by more specific CUI"

        return surviving, retention_map, removed


# ========================= TIER CLASSIFICATION =========================

class TierClassifier:
    """
    Search: leaves / near-leaves (depth ≤ median).
    Topic:  broad ancestors (depth > median).
    Guard: if all depths identical → all SEARCH.
    """

    def __init__(self, hierarchy: HierarchyClient):
        self.hierarchy = hierarchy

    @timed("tier_classification")
    def classify(self, cuis: List[str],
                 assessments: Dict[str, CUIAssessment]
                 ) -> Dict[str, CUIAssessment]:

        cui_set = set(cuis)
        depths = {cui: self.hierarchy.depth_to_nearest_leaf(cui, cui_set)
                  for cui in cuis}

        distinct = set(depths.values())
        if len(distinct) < 2:
            for cui in cuis:
                if cui in assessments:
                    assessments[cui].depth_from_leaf = depths.get(cui, 0)
                    assessments[cui].tier = Tier.SEARCH
            return assessments

        boundary = float(np.median(list(depths.values())))
        for cui in cuis:
            if cui in assessments:
                d = depths.get(cui, 0)
                assessments[cui].depth_from_leaf = d
                assessments[cui].tier = (
                    Tier.SEARCH if d <= boundary else Tier.TOPIC)

        log(f"  Tier boundary (median depth): {boundary:.1f}")
        return assessments


# ========================= EXPLANATION GENERATOR =========================

def generate_explanation(a: CUIAssessment,
                         weights: Dict[str, float],
                         metadata: Dict[str, CUIMetadata]) -> str:
    """Builds human-readable explanation for a surviving CUI."""

    parts = []

    # Relevance interpretation
    if a.relevance >= 0.8:
        parts.append(f"High relevance to text ({a.relevance:.2f})")
    elif a.relevance >= 0.6:
        parts.append(f"Moderate relevance to text ({a.relevance:.2f})")
    else:
        parts.append(f"Low relevance ({a.relevance:.2f}, kept by specificity)")

    # Specificity interpretation
    if a.specificity >= 0.8:
        parts.append(f"Highly specific concept (IC ratio={a.specificity:.2f})")
    elif a.specificity >= 0.5:
        parts.append(f"Moderately specific (IC ratio={a.specificity:.2f})")
    else:
        parts.append(f"Broad concept (IC ratio={a.specificity:.2f})")

    # Weights used
    parts.append(
        f"Weights: relevance={weights.get('relevance', 0.5):.2f}, "
        f"specificity={weights.get('specificity', 0.5):.2f}")

    # What it retains
    if a.retained_cuis:
        names = []
        for r in a.retained_cuis[:5]:  # cap display at 5
            m = metadata.get(r)
            names.append(f"'{m.preferred_term}'" if m else r)
        retains_str = ", ".join(names)
        if len(a.retained_cuis) > 5:
            retains_str += f" (+{len(a.retained_cuis) - 5} more)"
        parts.append(f"Retains: {retains_str}")

    # Tier
    tier_desc = ("leaf/near-leaf → document retrieval"
                 if a.tier == Tier.SEARCH
                 else "broad ancestor → topic label")
    parts.append(f"Tier: {a.tier.value} (depth={a.depth_from_leaf}, "
                 f"{tier_desc})")

    return " | ".join(parts)


# ========================= MAIN SYSTEM =========================

class CUIReductionSystem:
    """
    Production CUI reduction pipeline.

    Usage:
        system = CUIReductionSystem(project_id, dataset_id,
                                     network, allowed_sabs)
        result = system.reduce(cuis, text, cui_embeddings)

        result.search_cuis         → document retrieval
        result.topic_cuis          → topic labels
        result.assessments         → per-CUI scores + explanation
        result.removed             → every removed CUI + reason
        result.retention_map       → which ancestors each CUI explains
        result.weights             → variance-derived weights used
    """

    def __init__(
        self,
        project_id: str,
        dataset_id: str,
        network: nx.DiGraph,
        allowed_sabs: List[str],
        ic_scores: Optional[Dict[str, float]] = None,
        location: str = "us-central1",
        task_type: str = "SEMANTIC_SIMILARITY",
    ):
        self.bq = bigquery.Client(project=project_id)
        cache_size = network.number_of_nodes() * 2

        self.hierarchy = HierarchyClient(network, ic_scores, cache_size)
        self.fetcher = MetadataFetcher(
            self.bq, project_id, dataset_id,
            self.hierarchy, cache_size)
        self.sab_filter = SABFilter(set(allowed_sabs))
        self.embedder = TextEmbedder(project_id, location, task_type)
        self.retainer = HierarchyRetainer(self.hierarchy)
        self.tier_classifier = TierClassifier(self.hierarchy)

        log(f"CUIReductionSystem ready | sabs={allowed_sabs}")

    @timed("full_pipeline")
    def reduce(
        self,
        cuis: List[str],
        context_string: str,
        cui_embeddings: Dict[str, np.ndarray],
        usage_context: UsageContext = UsageContext.QUERY,
    ) -> ReductionResult:

        t0 = time.perf_counter()
        all_removed: Dict[str, str] = {}
        sc: Dict[str, int] = {"input": len(cuis)}

        if not cuis:
            return self._empty(context_string, usage_context, cuis,
                               all_removed, t0, sc)

        log(f"Reducing {len(cuis)} CUIs | "
            f"'{context_string[:80]}...'")

        # Stage 1: Metadata
        metadata = self.fetcher.fetch(cuis)
        sc["with_metadata"] = len(metadata)

        # Stage 2: SAB filter
        after_sab, sab_rm = self.sab_filter.run(cuis, metadata)
        all_removed.update(sab_rm)
        sc["after_sab"] = len(after_sab)
        log(f"  SAB: {len(cuis)} -> {len(after_sab)}")

        if not after_sab:
            return self._empty(context_string, usage_context, cuis,
                               all_removed, t0, sc)

        # Stage 3: Embed clinical text (validates dim against CUI embeddings)
        text_emb = self.embedder.embed(context_string, cui_embeddings)
        if text_emb is None:
            log("  WARNING: text embedding failed, using specificity only")

        # Stage 4: Score — relevance + specificity
        sab_meta = {c: metadata[c] for c in after_sab if c in metadata}
        assessments, weights = RelevanceSpecificityScorer.score(
            after_sab, sab_meta, text_emb, cui_embeddings)
        sc["scored"] = len(assessments)
        log(f"  Weights: {weights}")

        # Stage 5: Noise removal
        after_noise, noise_rm = NoiseRemover.run(after_sab, assessments)
        all_removed.update(noise_rm)
        sc["after_noise"] = len(after_noise)
        log(f"  Noise: {len(after_sab)} -> {len(after_noise)}")

        if not after_noise:
            return self._empty(context_string, usage_context, cuis,
                               all_removed, t0, sc, weights)

        # Stage 6: Hierarchy retention
        after_hier, rmap, hier_rm = self.retainer.run(
            after_noise, metadata)
        all_removed.update(hier_rm)
        sc["after_hierarchy"] = len(after_hier)
        log(f"  Hierarchy: {len(after_noise)} -> {len(after_hier)}")

        if not after_hier:
            return self._empty(context_string, usage_context, cuis,
                               all_removed, t0, sc, weights)

        # Stage 7: Tier classification
        assessments = self.tier_classifier.classify(
            after_hier, assessments)

        # Attach retention info to assessments
        for cui, retained in rmap.items():
            if cui in assessments:
                assessments[cui].retained_cuis = retained

        # Generate explanations
        for cui in after_hier:
            if cui in assessments:
                assessments[cui].explanation = generate_explanation(
                    assessments[cui], weights, metadata)

        # Sort tiers by confidence
        search, topics = [], []
        for cui in after_hier:
            a = assessments.get(cui)
            if not a:
                continue
            (search if a.tier == Tier.SEARCH else topics).append(cui)

        search.sort(key=lambda c: assessments[c].confidence,
                    reverse=True)
        topics.sort(key=lambda c: assessments[c].confidence,
                    reverse=True)
        all_surv = sorted(
            after_hier,
            key=lambda c: assessments[c].confidence,
            reverse=True)

        for rank, cui in enumerate(all_surv, 1):
            assessments[cui].ranking = rank

        sc.update({"search": len(search), "topics": len(topics),
                   "total_surviving": len(all_surv)})

        elapsed = (time.perf_counter() - t0) * 1000
        log(f"  Done: {len(cuis)} -> {len(all_surv)} "
            f"(search={len(search)}, topics={len(topics)}) "
            f"({elapsed:.0f}ms)")

        return ReductionResult(
            context_string=context_string,
            usage_context=usage_context,
            search_cuis=search,
            topic_cuis=topics,
            all_surviving=all_surv,
            assessments={c: assessments[c] for c in all_surv},
            retention_map=rmap,
            removed=all_removed,
            input_count=len(cuis),
            processing_time_ms=elapsed,
            stage_counts=sc,
            weights=weights,
        )

    @staticmethod
    def _empty(ctx, uc, cuis, removed, t0, sc, weights=None):
        return ReductionResult(
            ctx, uc, [], [], [], {}, {}, removed,
            len(cuis), (time.perf_counter() - t0) * 1000, sc,
            weights or {},
        )

    def get_stats(self) -> Dict:
        return get_timings()


# ========================= DYNAMIC VALIDATION =========================

@dataclass
class ValidationReport:
    """
    Self-assessment of reduction quality — no ground truth needed.
    Every metric is interpretable and has expected ranges.
    """
    # Overall
    reduction_ratio: float              # surviving / input (expect 0.05-0.40)
    is_healthy: bool                    # all checks passed

    # Relevance discrimination
    relevance_gap: float                # mean(survived) - mean(removed) relevance
    relevance_discriminative: bool      # gap > 0.05

    # Specificity gain
    specificity_gain: float             # mean(survived) - mean(removed) IC ratio
    specificity_favored: bool           # survivors are more specific

    # Hierarchy cleanliness
    residual_parent_child_pairs: int    # should be 0 after retention
    hierarchy_clean: bool

    # Tier balance
    search_count: int
    topic_count: int
    tier_degenerate: bool               # one tier has zero

    # Embedding coverage
    embedding_coverage: float           # fraction of CUIs with embeddings
    embedding_sufficient: bool          # > 50%

    # Weight balance
    weight_relevance: float
    weight_specificity: float
    weight_degenerate: bool             # one weight > 0.9

    # Component summary
    issues: List[str] = field(default_factory=list)

    def summary(self) -> str:
        status = "HEALTHY" if self.is_healthy else "ISSUES DETECTED"
        lines = [
            f"Validation: {status}",
            f"  Reduction: {self.reduction_ratio:.1%} survived",
            f"  Relevance gap: {self.relevance_gap:+.3f} "
            f"({'discriminative' if self.relevance_discriminative else 'WEAK'})",
            f"  Specificity gain: {self.specificity_gain:+.3f} "
            f"({'favored' if self.specificity_favored else 'NOT favored'})",
            f"  Hierarchy: {self.residual_parent_child_pairs} residual pairs "
            f"({'clean' if self.hierarchy_clean else 'DIRTY'})",
            f"  Tiers: {self.search_count} search, {self.topic_count} topic "
            f"({'balanced' if not self.tier_degenerate else 'DEGENERATE'})",
            f"  Embeddings: {self.embedding_coverage:.0%} coverage "
            f"({'sufficient' if self.embedding_sufficient else 'LOW'})",
            f"  Weights: rel={self.weight_relevance:.2f}, "
            f"spec={self.weight_specificity:.2f} "
            f"({'balanced' if not self.weight_degenerate else 'ONE-SIDED'})",
        ]
        if self.issues:
            lines.append(f"  Issues:")
            for issue in self.issues:
                lines.append(f"    - {issue}")
        return "\n".join(lines)


class DynamicValidator:
    """
    Validates reduction quality using internal consistency.
    No ground truth required — uses statistical properties
    of the output to detect problems.
    """

    @staticmethod
    def validate(
        result: ReductionResult,
        metadata: Dict[str, CUIMetadata],
        cui_embeddings: Dict[str, np.ndarray],
        hierarchy: 'HierarchyClient',
    ) -> ValidationReport:

        issues: List[str] = []
        surviving_set = set(result.all_surviving)
        removed_set = set(result.removed.keys())

        # --- Reduction ratio ---
        ratio = (len(result.all_surviving) / result.input_count
                 if result.input_count > 0 else 0)
        if ratio > 0.5:
            issues.append(
                f"High survival rate ({ratio:.0%}) — "
                f"system may not be reducing aggressively enough")
        elif ratio < 0.01 and result.input_count > 50:
            issues.append(
                f"Very low survival ({ratio:.0%}) — "
                f"scoring or noise threshold may be too aggressive")

        # --- Relevance discrimination ---
        surv_rel = [result.assessments[c].relevance
                    for c in result.all_surviving
                    if c in result.assessments]
        # For removed CUIs that had assessments (noise-removed, not sab/metadata)
        removed_rel = []
        for c in removed_set:
            reason = result.removed.get(c, "")
            if "noise" in reason or "redundant" in reason:
                # These had scores — estimate from the reason string
                pass
        # Use a simpler approach: check if surviving relevance is well above 0.5
        mean_surv_rel = float(np.mean(surv_rel)) if surv_rel else 0
        rel_gap = mean_surv_rel - 0.5  # above random baseline
        rel_discriminative = rel_gap > 0.05
        if not rel_discriminative:
            issues.append(
                f"Relevance scores near baseline (mean={mean_surv_rel:.3f}) — "
                f"text embedding may not match CUI embedding space")

        # --- Specificity gain ---
        surv_spec = [result.assessments[c].specificity
                     for c in result.all_surviving
                     if c in result.assessments]
        mean_surv_spec = float(np.mean(surv_spec)) if surv_spec else 0

        all_spec = [metadata[c].ic_score for c in metadata]
        mean_all_spec_norm = (float(np.mean(all_spec)) / max(all_spec)
                              if all_spec and max(all_spec) > 0 else 0)
        spec_gain = mean_surv_spec - mean_all_spec_norm
        spec_favored = spec_gain > 0
        if not spec_favored:
            issues.append(
                f"Survivors not more specific than input average "
                f"(gain={spec_gain:+.3f}) — hierarchy retention "
                f"may not be removing enough ancestors")

        # --- Hierarchy cleanliness ---
        residual_pairs = 0
        for cui in result.all_surviving:
            parents = hierarchy.get_parents(cui)
            for p in parents:
                if p in surviving_set:
                    residual_pairs += 1
        hier_clean = residual_pairs == 0
        if not hier_clean:
            issues.append(
                f"{residual_pairs} parent-child pairs remain in output — "
                f"hierarchy retention has gaps")

        # --- Tier balance ---
        n_search = len(result.search_cuis)
        n_topic = len(result.topic_cuis)
        tier_degenerate = (n_search == 0 or n_topic == 0) and (
            n_search + n_topic > 5)
        if tier_degenerate:
            issues.append(
                f"Degenerate tiers: {n_search} search, {n_topic} topic — "
                f"all CUIs at same hierarchy depth")

        # --- Embedding coverage ---
        total_after_sab = result.stage_counts.get("after_sab", 1)
        emb_coverage = (len(cui_embeddings) / total_after_sab
                        if total_after_sab > 0 else 0)
        emb_sufficient = emb_coverage > 0.5
        if not emb_sufficient:
            issues.append(
                f"Low embedding coverage ({emb_coverage:.0%}) — "
                f"relevance scoring is degraded for {100 - emb_coverage * 100:.0f}% of CUIs")

        # --- Weight balance ---
        w_rel = result.weights.get("relevance", 0.5)
        w_spec = result.weights.get("specificity", 0.5)
        weight_degen = max(w_rel, w_spec) > 0.9
        if weight_degen:
            dominant = "relevance" if w_rel > w_spec else "specificity"
            issues.append(
                f"Weights heavily skewed to {dominant} "
                f"({w_rel:.2f}/{w_spec:.2f}) — "
                f"one signal has very low variance")

        is_healthy = len(issues) == 0

        return ValidationReport(
            reduction_ratio=ratio,
            is_healthy=is_healthy,
            relevance_gap=rel_gap,
            relevance_discriminative=rel_discriminative,
            specificity_gain=spec_gain,
            specificity_favored=spec_favored,
            residual_parent_child_pairs=residual_pairs,
            hierarchy_clean=hier_clean,
            search_count=n_search,
            topic_count=n_topic,
            tier_degenerate=tier_degenerate,
            embedding_coverage=emb_coverage,
            embedding_sufficient=emb_sufficient,
            weight_relevance=w_rel,
            weight_specificity=w_spec,
            weight_degenerate=weight_degen,
            issues=issues,
        )


# ========================= UTILITIES =========================

class CUIExtractor:
    """Calls CUI extraction API. Returns list of CUI strings."""

    def __init__(self, api_url: str):
        self.url = api_url
        self.session = requests.Session()
        try:
            token = subprocess.run(
                ["gcloud", "auth", "print-identity-token"],
                stdout=subprocess.PIPE, universal_newlines=True,
                timeout=30,
            ).stdout.strip()
            self.headers = {"Authorization": f"Bearer {token}",
                            "Content-Type": "application/json"}
        except Exception:
            self.headers = {"Content-Type": "application/json"}

        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry
        retry = Retry(total=3, backoff_factor=1,
                      status_forcelist=[429, 500, 502, 503, 504])
        self.session.mount("https://", HTTPAdapter(max_retries=retry))

    def extract(self, text: str) -> List[str]:
        """Returns deduplicated list of CUI strings."""
        try:
            resp = self.session.post(
                self.url, headers=self.headers,
                json={"query_texts": [text], "top_k": 3},
                timeout=200,
            )
            resp.raise_for_status()
            data = resp.json()
            if not isinstance(data, dict):
                return []

            cuis = []
            for val in data.values():
                if not isinstance(val, list):
                    continue
                for item in val:
                    if isinstance(item, dict) and "cui" in item:
                        cuis.append(str(item["cui"]))
                    elif isinstance(item, str) and item.strip():
                        cuis.append(item.strip())
            return list(set(cuis))
        except Exception as e:
            log(f"Extraction failed: {e}", "ERROR")
            return []


def fetch_cui_embeddings(
    cuis: List[str], pid: str, did: str, table: str,
) -> Dict[str, np.ndarray]:
    """Fetch pre-computed CUI embeddings from BigQuery."""
    if not cuis:
        return {}
    client = bigquery.Client(project=pid)
    embs: Dict[str, np.ndarray] = {}
    for i in range(0, len(cuis), _BQ_BATCH_SIZE):
        batch = cuis[i:i + _BQ_BATCH_SIZE]
        q = (f"SELECT CUI, embedding FROM `{pid}.{did}.{table}` "
             f"WHERE CUI IN UNNEST(@c)")
        jc = bigquery.QueryJobConfig(query_parameters=[
            bigquery.ArrayQueryParameter("c", "STRING", batch)])
        try:
            for r in client.query(q, job_config=jc, timeout=200).result():
                arr = np.asarray(r.embedding, dtype=np.float64)
                if arr.ndim == 1 and np.all(np.isfinite(arr)):
                    embs[r.CUI] = arr
        except Exception as e:
            log(f"Embedding fetch error (batch {i}): {e}", "ERROR")
    return embs


# ========================= MAIN =========================

def main():
    """Run CUI reduction for clinical texts."""
    import pickle

    # ---- Configuration ----
    PROJECT_ID = "your-project-id"
    DATASET_ID = "your-dataset"
    API_URL = "https://your-api/extract"
    EMBEDDING_TABLE = "cui_embeddings"
    NETWORK_PATH = "networkx_cui_context_v1_1_0.pkl"
    ALLOWED_SABS = ["ICD10CM", "ICD10PCS", "ICD9CM",
                     "SNOMEDCT_US", "LOINC"]
    LOCATION = "us-central1"

    # ---- Load hierarchy ----
    log("Loading hierarchy...")
    with open(NETWORK_PATH, "rb") as f:
        network = pickle.load(f)
    log(f"Loaded: {network.number_of_nodes()} nodes, "
        f"{network.number_of_edges()} edges")

    # ---- Initialize ----
    system = CUIReductionSystem(
        PROJECT_ID, DATASET_ID, network, ALLOWED_SABS,
        location=LOCATION)
    extractor = CUIExtractor(API_URL)

    # ---- Process ----
    texts = [
        "Patient has severe pain in left knee with swelling",
        "History of type 2 diabetes mellitus with peripheral neuropathy",
        "Acute exacerbation of chronic obstructive pulmonary disease",
    ]

    for text in texts:
        log(f"\n{'='*60}")
        log(f"TEXT: {text}")
        log(f"{'='*60}")

        # Extract CUIs
        cuis = extractor.extract(text)
        if not cuis:
            log("  No CUIs extracted")
            continue
        log(f"  Extracted: {len(cuis)} CUIs")

        # Fetch CUI embeddings
        cui_embs = fetch_cui_embeddings(
            cuis, PROJECT_ID, DATASET_ID, EMBEDDING_TABLE)
        log(f"  Embeddings: {len(cui_embs)}/{len(cuis)}")

        # Reduce
        result = system.reduce(cuis, text, cui_embs)

        # ---- Dynamic Validation (no ground truth needed) ----
        metadata = system.fetcher.fetch(cuis)
        report = DynamicValidator.validate(
            result, metadata, cui_embs, system.hierarchy)
        log(f"\n{report.summary()}")

        # ---- Display results ----
        log(f"\n  Stage counts: {result.stage_counts}")
        log(f"  Weights used: {result.weights}")

        log(f"\n  --- Search CUIs ({len(result.search_cuis)}) ---")
        for cui in result.search_cuis:
            a = result.assessments[cui]
            log(f"    #{a.ranking} {a.preferred_term} ({cui})")
            log(f"      confidence={a.confidence:.3f} "
                f"relevance={a.relevance:.3f} "
                f"specificity={a.specificity:.3f}")
            log(f"      {a.explanation}")

        log(f"\n  --- Topic CUIs ({len(result.topic_cuis)}) ---")
        for cui in result.topic_cuis:
            a = result.assessments[cui]
            log(f"    #{a.ranking} {a.preferred_term} ({cui})")
            log(f"      confidence={a.confidence:.3f} "
                f"relevance={a.relevance:.3f} "
                f"specificity={a.specificity:.3f}")
            log(f"      {a.explanation}")

        log(f"\n  --- Removed ({len(result.removed)}) ---")
        reasons = defaultdict(int)
        for cui, reason in result.removed.items():
            category = reason.split(" ")[0].split("(")[0].strip()
            reasons[category] += 1
        for reason, count in sorted(reasons.items(),
                                     key=lambda x: -x[1]):
            log(f"    {reason}: {count} CUIs")

    # Stats
    log(f"\n{'='*60}")
    log("PERFORMANCE:")
    for name, stats in system.get_stats().items():
        log(f"  {name}: mean={stats['mean_ms']:.1f}ms, "
            f"p99={stats['p99_ms']:.1f}ms")


if __name__ == "__main__":
    main()
