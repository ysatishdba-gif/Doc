# %% Retention: 1 embedding call + existing pipeline data

from google import genai
from collections import defaultdict

client = genai.Client(vertexai=True, project=PROJECT_ID, location="us-central1")

def compute_retention(text, result, embs, ic_precomputed, metadata_cache):
    """
    Information Retention Scoring.

    Measures how much of the user's narrative each CUI retains,
    considering specificity, qualifiers, and semantic alignment.

    Input:  CUIs, context_string, existing pipeline data
    Output: sorted CUIs with retention scores + explains sets

    Cost: 1 embedding API call (~100ms, ~$0.0001)
    Everything else reuses data already in memory.
    """

    surviving = result.all_reduced_cuis
    if not surviving:
        return [], {}

    # ── ONE embedding call: text -> 3072-dim vector ──
    response = client.models.embed_content(
        model="gemini-embedding-001",
        contents=text,
    )
    text_vec = np.array(response.embeddings[0].values, dtype=np.float32)
    text_vec = text_vec / (np.linalg.norm(text_vec) + 1e-10)

    # ── Narrative alignment: cosine(text_vec, cui_vec) ──
    # This is what actually answers "does this CUI match what the patient said?"
    # Handles synonyms: "swelling" matches "edema", "pain" matches "arthralgia"
    # Handles qualifiers: "left knee" scores higher than "right hip"
    alignments = {}
    for cui in surviving:
        if cui in embs:
            alignments[cui] = max(0.0, float(np.dot(text_vec, embs[cui])))
        else:
            alignments[cui] = 0.0

    # ── Explains map from audit trail (already computed) ──
    explains = defaultdict(set)
    for entry in result.audit_trail:
        if entry.kept_cui and entry.removed_cui:
            explains[entry.kept_cui].add(entry.removed_cui)

    # ── IC within surviving set (already computed) ──
    ic_vals = {c: ic_precomputed.get(c, 0.0) for c in surviving}
    ic_arr = list(ic_vals.values())
    ic_min, ic_max = min(ic_arr), max(ic_arr)
    ic_range = ic_max - ic_min if ic_max > ic_min else 1.0

    # ── Score: alignment-first, IC as tiebreaker ──
    # No hardcoded weights: derive from variance
    align_arr = np.array([alignments.get(c, 0.0) for c in surviving])
    ic_norm = np.array([(ic_vals[c] - ic_min) / ic_range for c in surviving])
    explain_arr = np.array([len(explains.get(c, set())) for c in surviving], dtype=float)
    ex_max = explain_arr.max() if explain_arr.max() > 0 else 1.0
    explain_arr = explain_arr / ex_max

    features = np.column_stack([align_arr, ic_norm, explain_arr])
    var = features.var(axis=0)
    weights = var / (var.sum() + 1e-10)
    print(f"Data-derived weights: alignment={weights[0]:.3f}, "
          f"specificity={weights[1]:.3f}, explains={weights[2]:.3f}")

    scores = features @ weights

    # ── Build output ──
    retention = {}
    for i, cui in enumerate(surviving):
        m = metadata_cache.get(cui)
        if not m:
            continue
        retention[cui] = {
            "score": round(float(scores[i]), 4),
            "alignment": round(float(alignments.get(cui, 0.0)), 3),
            "ic_local": round(float(ic_norm[i]), 3),
            "explains_count": len(explains.get(cui, set())),
            "term": m.preferred_term,
            "semantic_types": m.semantic_types,
            "explains_cuis": list(explains.get(cui, set())),
        }

    sorted_cuis = sorted(retention.keys(),
                          key=lambda c: retention[c]["score"], reverse=True)

    return sorted_cuis, retention


# %% Run
metadata_cache = {c: system.fetcher._cache.get(c)
                  for c in result.all_reduced_cuis
                  if system.fetcher._cache.get(c)}

sorted_cuis, retention = compute_retention(
    text, result, embs, ic_precomputed, metadata_cache)

print(f"\nTop 30 CUIs by retention score:")
for c in sorted_cuis[:30]:
    r = retention[c]
    stys = ", ".join(r["semantic_types"][:2]) if r["semantic_types"] else "?"
    line = (f"  {c} | score={r['score']} "
            f"(align={r['alignment']}, spec={r['ic_local']}, "
            f"explains={r['explains_count']}) "
            f"| [{stys}] {r['term']}")
    if r["explains_count"] > 0:
        line += f" | explains {r['explains_count']}"
    print(line)
