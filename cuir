# %% Retention v3: token F1 alignment + embedding as tiebreaker

# extract meaningful tokens from input text (drop stopwords)
stopwords = {"a","an","the","in","of","with","has","had","is","was","for",
             "to","and","or","on","at","by","no","not","patient","history"}

def text_tokens(text):
    tokens = tokenize_term(normalize_term(text))
    return tokens - stopwords

input_tokens = text_tokens(text)
print(f"Input tokens: {input_tokens}")

# build focused context vector from top token-matching CUIs
embs = system.emb_fetcher.fetch(result.all_reduced_cuis)

token_scores = {}
for cui in result.all_reduced_cuis:
    m = system.fetcher._cache.get(cui)
    if not m or not m.term_tokens:
        continue
    cui_tokens = m.term_tokens - stopwords
    if not cui_tokens:
        continue
    overlap = cui_tokens & input_tokens
    precision = len(overlap) / len(cui_tokens)       # CUI tokens found in input
    recall = len(overlap) / len(input_tokens)         # input tokens found in CUI
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0
    token_scores[cui] = (f1, precision, recall)

# context vector from top-20 token-matching CUIs (focused, not generic centroid)
top_token = sorted(token_scores.keys(), key=lambda c: token_scores[c][0], reverse=True)[:20]
focus_vecs = [embs[c] for c in top_token if c in embs]
if focus_vecs:
    ctx_vec = np.mean(focus_vecs, axis=0)
    ctx_vec = ctx_vec / (np.linalg.norm(ctx_vec) + 1e-10)

retention = {}
for cui in result.all_reduced_cuis:
    m = system.fetcher._cache.get(cui)
    if not m:
        continue

    # token F1 (primary: does CUI match the actual narrative?)
    f1, prec, rec = token_scores.get(cui, (0.0, 0.0, 0.0))

    # embedding alignment to focused context (secondary: synonym handling)
    if cui in embs and ctx_vec is not None:
        emb_sim = max(0.0, float(np.dot(embs[cui], ctx_vec)))
    else:
        emb_sim = 0.0

    # IC rank among surviving CUIs (tiebreaker only)
    ic_raw = m.ic_score

    # weighted: 50% token F1, 35% embedding, 15% IC-based
    score = 0.50 * f1 + 0.35 * emb_sim + 0.15 * min(ic_raw / 14.80, 1.0)

    retention[cui] = {
        "score": round(score, 4),
        "f1": round(f1, 3),
        "precision": round(prec, 3),
        "recall": round(rec, 3),
        "emb_sim": round(emb_sim, 3),
        "term": m.preferred_term,
    }

explains = defaultdict(list)
for entry in result.audit_trail:
    if entry.kept_cui and entry.removed_cui:
        explains[entry.kept_cui].append(entry.removed_cui)

sorted_cuis = sorted(retention.keys(), key=lambda c: retention[c]["score"], reverse=True)

print(f"\nTop 25 CUIs by retention score:")
for c in sorted_cuis[:25]:
    r = retention[c]
    explained = explains.get(c, [])
    line = (f"  {c} | score={r['score']} "
            f"(F1={r['f1']}, P={r['precision']}, R={r['recall']}, emb={r['emb_sim']}) "
            f"| {r['term']}")
    if explained:
        line += f" | explains {len(explained)}"
    print(line)
