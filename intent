"""
Production-Ready Version - Following YOUR TEAM'S Pattern

Based on your team's main.py production code:
1. Schema passed as separate parameter (not in config)
2. Utility function handles schema conversion
3. Clean separation of concerns

Key from your team's code:
config["response_mime_type"] = "application/json"
config["response_schema"] = None  # Set separately via utility
Then: run_genai(client, prompt, schema, model, config=config)
"""

import json
import re
from datetime import datetime
from typing import Dict, Any, List, Optional
from google.cloud import aiplatform
from vertexai.generative_models import GenerativeModel
from pydantic import BaseModel, Field


# ============================================================================
# UTILITY FUNCTION (Team's pattern from utils.py)
# ============================================================================

def clean_schema_for_gemini(schema: Dict[str, Any]) -> Dict[str, Any]:
    """
    Clean Pydantic schema for Gemini compatibility.
    Removes $defs and inlines nested model references.
    """
    schema = json.loads(json.dumps(schema))
    defs = schema.pop('$defs', {})
    
    def resolve_refs(obj):
        if isinstance(obj, dict):
            if '$ref' in obj:
                ref = obj['$ref']
                if ref.startswith('#/$defs/'):
                    def_name = ref.split('/')[-1]
                    if def_name in defs:
                        return resolve_refs(defs[def_name].copy())
                return obj
            return {k: resolve_refs(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [resolve_refs(item) for item in obj]
        return obj
    
    return resolve_refs(schema)


def run_genai(
    model: GenerativeModel,
    prompt: str,
    schema: Optional[BaseModel],
    model_name: str,
    config: Dict[str, Any]
) -> Any:
    """
    Generate content with schema - following team's run_genai pattern.
    
    This matches the signature from your team's production code:
    run_genai(client, prompt, schema, genai_model_name, config=config)
    """
    generation_config = config.copy()
    
    # Following team's pattern: set these in config
    generation_config["response_mime_type"] = "application/json"
    
    if schema:
        # Convert Pydantic schema and clean for Gemini
        raw_schema = schema.model_json_schema()
        cleaned_schema = clean_schema_for_gemini(raw_schema)
        generation_config["response_schema"] = cleaned_schema
    
    # Generate content
    response = model.generate_content(
        prompt,
        generation_config=generation_config
    )
    
    return response


# ============================================================================
# SCHEMA DEFINITIONS
# ============================================================================

class SubNature(BaseModel):
    category_path: str
    atomic_concepts: List[str]


class IntentFull(BaseModel):
    intent_title: str
    description: str
    nature: str
    sub_natures: List[SubNature]
    final_queries: List[str]


class FullIntentExtractionOutput(BaseModel):
    is_clinical: bool
    original_query: str
    expanded_query: str
    total_intents_detected: int
    intents: List[IntentFull]
    reason: str = ""


class QueryExpansionOutput(BaseModel):
    expanded_query: str
    abbreviations_expanded: List[str] = Field(default_factory=list)


# Output 1: Intent Extractions
class IntentBasic(BaseModel):
    intent_title: str
    description: str


class IntentExtractionsOutput(BaseModel):
    original_query: str
    expanded_query: str
    count_of_intents: int
    intents: List[IntentBasic]


# Output 2: Nature Breakdown
class IntentWithNature(BaseModel):
    intent_title: str
    description: str
    nature: str
    sub_natures: List[SubNature]


class NatureBreakdownOutput(BaseModel):
    original_query: str
    expanded_query: str
    count_of_intents: int
    intents: List[IntentWithNature]


# Output 3: Queries (for CUI extraction)
class IntentQueries(BaseModel):
    intent_title: str
    final_queries: List[str]


class QueriesOutput(BaseModel):
    original_query: str
    expanded_query: str
    count_of_intents: int
    total_queries: int
    intents: List[IntentQueries]
    all_queries: List[str]


# ============================================================================
# PROMPTS - UNCHANGED
# ============================================================================

QUERY_EXPANSION_PROMPT = """
You are an expert medical AI assistant specializing in clinical query expansion.

TASK: Expand the user's query into a comprehensive, detailed clinical description.

INSTRUCTIONS:
1. Expand ALL medical abbreviations to full terms (e.g., HTN → Hypertension, DM → Diabetes Mellitus, SOB → Shortness of Breath)
2. Clarify vague medical terms with specific clinical language
3. Add relevant medical context based on standard clinical practice
4. Identify implicit clinical concepts that should be explicit
5. DO NOT add assumptions beyond reasonable clinical interpretation
6. DO NOT include action verbs like "analyze", "review", "check" unless in original query
7. DO NOT hallucinate information not implied by the query
8. Maintain the original query's intent and scope
9.Make sure the Temporal accept is relevant to the Query context

EXAMPLES:
- "Pt with DM" → "Patient with Diabetes Mellitus"
- "Check vitals" → "Vital signs measurement including blood pressure, heart rate, temperature, respiratory rate, oxygen saturation"
- "Family hx of heart disease" → "Cardiovascular disease in family including coronary artery disease, myocardial infarction, heart failure"
- "SOB on exertion" → "Shortness of breath on exertion"

Return ONLY valid JSON (no markdown, no explanation):
{{
  "expanded_query": "comprehensive expanded clinical description",
  "abbreviations_expanded": ["list of abbreviations that were expanded"] 
}}

User Input: {query}
"""

INTENT_EXTRACTION_PROMPT = """
You are a clinical intent extraction engine for medical document retrieval.

====================================================
CLINICAL VALIDATION
====================================================

Return this ONLY if query is non-clinical:
{{"is_clinical": false, "reason": "Query is not clinical in nature", "intents": []}}

====================================================
CORE PRINCIPLES
====================================================

**Extraction Philosophy:**
When someone requests clinical information, extract everything needed to fully understand, act upon, or make decisions about that information safely and effectively.

**Guiding Questions:**
1. What is being requested?
2. What contextual information is inseparable from this concept?
3. What would be incomplete or unsafe without?
4. How is this information naturally organized?

**Inseparability Concept:**
Some information types are inherently connected for safety, understanding, or completeness. When extracting one, consider whether the other is contextually necessary.

====================================================
INTENT GENERATION
====================================================

**Analyze the expanded query and identify distinct clinical intents.**

Each intent represents a clinically independent concept that could be documented or understood separately.

Generate as many intents as the expanded query contains. Let the content guide the count.

====================================================
INTENT STRUCTURE
====================================================

For each intent:

1. **intent_title** - What is this about?
2. **description** - What does this represent and why does it matter?
3. **nature** - What is the primary informational purpose? (Format: [Context] / [Purpose])
4. **sub_natures[]** - What are the distinct dimensions of this information?
5. **final_queries[]** - How would this appear in clinical documents?

====================================================
SUB_NATURE DECOMPOSITION
====================================================

**Core Question: "What are the meaningful aspects of this clinical concept?"**

Structure:
{{
  "category_path": "Broad >> Specific >> Detail",
  "atomic_concepts": ["terminal1", "terminal2"]
}}

**CATEGORY_PATH:**
Think of this as organizing information from general to specific. Each level adds meaningful distinction. Use " >> " as the separator.

Consider: "How would I navigate to this information?"

**ATOMIC_CONCEPTS:**
These are the actual data points - the most specific, granular elements at the end of the navigation path.

Consider: "What are the specific pieces of information needed?"

Include all specific details mentioned: exact values, names, dates, measurements, descriptors.

**Key Understanding:**
- category_path = How to get there (the folders)
- atomic_concepts = What's there (the files - be specific)

**Dimension Identification:**
Consider: "What different types of information exist for this concept?"
- Names and identifiers?
- Measurements and quantities?
- Time-related information?
- Location information?
- Characteristics and qualities?
- Relationships and connections?
- Safety-related information?
- People involved?
- Current state or status?
- Surrounding circumstances?

Extract the dimensions that are present and relevant.

**Grouping Logic:**
If multiple pieces of information answer the same type of question, group them in one sub_nature. Build depth in the category_path rather than creating many shallow sub_natures.

====================================================
FINAL_QUERIES: ATOMIC SPECIFICITY
====================================================

**Purpose:**
Generate concise, atomic-level queries that map to precise clinical concepts without generating excessive CUIs.

**Core Insight:**
Long verbose queries generate too many CUIs. Short atomic queries target specific concepts.

Consider the difference:
-  "metformin 500mg twice daily for diabetes management" → generates 10+ CUIs, which is not required
- ✓ "metformin 500mg" → generates 2-3 focused CUIs
- ✓ "twice daily dosing" → generates 1-2 CUIs

**Atomic Query Principle:**
Each query should represent ONE atomic clinical concept or a tight pairing of inseparable concepts.

Think: "What's the smallest meaningful unit?"
- A specific medication + dose
- A specific measurement + value
- A specific condition + severity
- A specific procedure + site

**Generation Approach:**

Extract atomic_concepts directly as queries. Keep them SHORT and PRECISE.

**Guiding Questions:**
- What's the core medical term?
- Is there ONE essential modifier (dose, site, severity)?
- Can this be made shorter while staying meaningful?
- Will this generate a focused set of CUIs?

**Query Characteristics:**
- 2-4 words maximum
- One clinical concept per query
- Include only essential modifiers
- Use standard medical terminology
- Each query → 1-3 CUIs ideally

**Natural Reasoning:**
- Shorter = fewer CUIs = more precise matching
- Atomic = focused = findable
- Multiple short queries > one long query
- Coverage through quantity, not length

**Coverage:**
Generate multiple atomic queries per intent. Each atomic_concept should appear in at least one query, but keep each query short and focused.

====================================================
REASONING FRAMEWORK
====================================================

**Before finalizing, consider:**

On Completeness:
- Have all distinct intents in the expanded query been identified?
- For each intent, have all relevant dimensions been extracted?
- Is there information that's inseparable from what was extracted?

On Specificity:
- Are atomic_concepts as specific as possible?
- Have actual values been included, not just categories?
- Are queries detailed enough to be useful?

On Structure:
- Does each sub_nature represent a different type of information?
- Are atomic_concepts truly the most granular elements?
- Is information properly organized?

On Utility:
- Would someone find what they need with these queries?
- Are the queries realistic for clinical documentation?
- Do the queries cover all the important atomic_concepts?

====================================================
OUTPUT FORMAT
====================================================

{{
  "is_clinical": true,
  "reason": "",
  "original_query": "{original_query}",
  "expanded_query": "{expanded_query}",
  "total_intents_detected": <number>,
  "intents": [
    {{
      "intent_title": "<string>",
      "description": "<string>",
      "nature": "<string>",
      "sub_natures": [
        {{
          "category_path": "<Broad >> Specific >> Detail>",
          "atomic_concepts": ["<concept1>", "<concept2>"]
        }}
      ],
      "final_queries": ["<query1>", "<query2>", "<query3>", "..."]
    }}
  ]
}}

User Input: {expanded_query}
Timestamp: {timestamp}
"""


# ============================================================================
# PIPELINE CLASS
# ============================================================================

class ContextualIntentPipeline:    
    def __init__(self, project: str, location: str = "us-central1", 
                 model: str = "gemini-2.0-flash-exp"):

        aiplatform.init(project=project, location=location)
        self.model = GenerativeModel(model)
        self.model_name = model
        
    def _call_model(self, prompt: str, schema: Optional[BaseModel] = None,
                    config: Optional[Dict[str, Any]] = None) -> Any:
        """
        Call model following team's pattern.
        Schema passed as separate parameter.
        """
        try:
            # Reset session
            if hasattr(self.model, "session") and self.model.session is not None:
                self.model.session.reset()
            
            # Default config
            if config is None:
                config = {
                    "temperature": 0.0,
                    "max_output_tokens": 8096,
                    "top_p": 1.0,
                    "top_k": 1,
                    "seed": 34
                }
            
            # Use team's run_genai pattern
            response = run_genai(
                self.model,
                prompt,
                schema,
                self.model_name,
                config=config
            )
            
            return response
        except Exception as e:
            print(f"Error calling model: {str(e)}")
            raise
    
    def _safe_json(self, text: str) -> Dict[str, Any]:
        # Remove markdown
        text = re.sub(r'```json\s*', '', text)
        text = re.sub(r'```\s*', '', text)
        text = text.strip()
        
        try:
            return json.loads(text)
        except json.JSONDecodeError:
            match = re.search(r'\{.*\}', text, re.DOTALL)
            if match:
                try:
                    return json.loads(match.group(0))
                except:
                    pass
            print(f"Failed to parse JSON: {text[:200]}")
            return {}
    
    def _validate_json_structure(self, data: Dict, required_keys: List[str]) -> bool:
        return all(key in data for key in required_keys)
    
    def expand_query(self, query: str) -> Dict[str, Any]:
        prompt = QUERY_EXPANSION_PROMPT.format(query=query)
        config = {
            "temperature": 0.0,
            "max_output_tokens": 2048,
            "top_p": 1.0,
            "top_k": 1,
            "seed": 34
        }
        
        raw_response = self._call_model(prompt, schema=QueryExpansionOutput, config=config)
        data = self._safe_json(raw_response.text)
        
        if not self._validate_json_structure(data, ["expanded_query"]):
            return {
                "expanded_query": query,
                "abbreviations_expanded": [],
            }
        
        return {
            "expanded_query": data.get("expanded_query", query),
            "abbreviations_expanded": data.get("abbreviations_expanded", []),
        }
    
    def extract_intents(self, original_query: str, expanded_query: str) -> Dict[str, Any]:
        prompt = INTENT_EXTRACTION_PROMPT.format(
            original_query=original_query,
            expanded_query=expanded_query,
            timestamp=datetime.utcnow().isoformat()
        )
        
        config = {
            "temperature": 0.0,
            "max_output_tokens": 8096,
            "top_p": 1.0,
            "top_k": 1,
            "seed": 34
        }
        
        raw_response = self._call_model(prompt, schema=FullIntentExtractionOutput, config=config)
        data = self._safe_json(raw_response.text)
        
        if not data.get("is_clinical", True):
            return {
                "intents": [],
                "total_intents_detected": 0,
                "is_clinical": False,
                "rejected_reason": data.get("reason", "Query is not clinical"),
                "original_query": original_query,
                "expanded_query": expanded_query
            }
        
        if not self._validate_json_structure(data, ["intents"]):
            return {
                "intents": [],
                "total_intents_detected": 0,
                "error": "Failed to extract intents"
            }
        
        intents = data.get("intents", [])
        validated_intents = []
        
        for idx, intent in enumerate(intents):
            if "final_queries" not in intent or not intent["final_queries"]:
                print(f"  Warning: Intent {idx + 1} '{intent.get('intent_title', 'Unknown')}' has no final_queries. Skipping.")
                continue
            validated_intents.append(intent)
        
        return {
            "intents": validated_intents,
            "total_intents_detected": data.get("total_intents_detected", len(validated_intents)),
            "is_clinical": True,
            "original_query": data.get("original_query", original_query),
            "expanded_query": data.get("expanded_query", expanded_query)
        }    
    
    def convert_to_intent_extractions(self, full_result: Dict[str, Any]) -> Dict[str, Any]:
        return {
            "original_query": full_result["original_query"],
            "expanded_query": full_result["expanded_query"],
            "count_of_intents": len(full_result["intents"]),
            "intents": [
                {
                    "intent_title": intent["intent_title"],
                    "description": intent["description"]
                }
                for intent in full_result["intents"]
            ]
        }
    
    def convert_to_nature_breakdown(self, full_result: Dict[str, Any]) -> Dict[str, Any]:
        return {
            "original_query": full_result["original_query"],
            "expanded_query": full_result["expanded_query"],
            "count_of_intents": len(full_result["intents"]),
            "intents": [
                {
                    "intent_title": intent["intent_title"],
                    "description": intent["description"],
                    "nature": intent["nature"],
                    "sub_natures": intent["sub_natures"]
                }
                for intent in full_result["intents"]
            ]
        }
    
    def convert_to_queries(self, full_result: Dict[str, Any]) -> Dict[str, Any]:
        all_queries = []
        for intent in full_result["intents"]:
            all_queries.extend(intent["final_queries"])
        
        return {
            "original_query": full_result["original_query"],
            "expanded_query": full_result["expanded_query"],
            "count_of_intents": len(full_result["intents"]),
            "total_queries": len(all_queries),
            "intents": [
                {
                    "intent_title": intent["intent_title"],
                    "final_queries": intent["final_queries"]
                }
                for intent in full_result["intents"]
            ],
            "all_queries": all_queries
        }
    
    def run(self, query: str, output_type: str = "full", verbose: bool = False) -> Dict[str, Any]:
        start_time = datetime.utcnow()
        
        if verbose:
            print(f"Original Query: {query}")
        
        expansion_result = self.expand_query(query)
        expanded_query = expansion_result["expanded_query"]
        
        if verbose:
            print(f"Expanded Query: {expanded_query}")
        
        intent_result = self.extract_intents(query, expanded_query)
        
        if not intent_result.get("is_clinical", True):
            processing_time = (datetime.utcnow() - start_time).total_seconds()
            if verbose:
                print(f"Status: NON-CLINICAL (rejected)")
                print(f"Processing Time: {processing_time:.2f}s\n")
            
            return {
                "original_query": query,
                "expanded_query": expanded_query,
                "intents": [],
                "is_clinical": False,
                "rejected_reason": intent_result.get("rejected_reason", "Query is not clinical"),
                "timestamp": datetime.utcnow().isoformat(),
                "processing_time_seconds": processing_time
            }
        
        intents = intent_result.get("intents", [])        
        total_queries = sum(len(intent.get('final_queries', [])) for intent in intents)
        total_sub_natures = sum(len(intent.get('sub_natures', [])) for intent in intents)
        processing_time = (datetime.utcnow() - start_time).total_seconds()
        
        if verbose:
            print(f"Status: CLINICAL")
            print(f"Intents: {len(intents)} | Sub-natures: {total_sub_natures} | Queries: {total_queries}")
            print(f"Processing Time: {processing_time:.2f}s\n")
        
        full_result = {
            "original_query": query,
            "expanded_query": expanded_query,
            "abbreviations_expanded": expansion_result.get("abbreviations_expanded", []),
            "is_clinical": True,
            "intents": intents,            
            "timestamp": datetime.utcnow().isoformat(),
            "processing_time_seconds": processing_time
        }
        
        if output_type == "intent_extractions":
            return self.convert_to_intent_extractions(full_result)
        elif output_type == "nature_breakdown":
            return self.convert_to_nature_breakdown(full_result)
        elif output_type == "queries":
            return self.convert_to_queries(full_result)
        else:
            return full_result


if __name__ == "__main__":
    PROJECT_ID = "your-project-id"  # CHANGE THIS
    
    pipeline = ContextualIntentPipeline(
        project=PROJECT_ID,
        location="us-central1",
        model="gemini-2.0-flash-exp"
    )
    
    test_queries = ["history of Glioblastoma in the last 6 years"]
    
    for idx, query in enumerate(test_queries, 1):
        print(f"\n{'='*80}")
        print(f"Query {idx}/{len(test_queries)}")
        print(f"{'='*80}")
        
        result = pipeline.run(query, output_type="queries", verbose=True)
        
        output_filename = f"query_result_{idx}.json"
        with open(output_filename, 'w') as f:
            json.dump(result, f, indent=2)
        
        print(f"Saved to: {output_filename}")
