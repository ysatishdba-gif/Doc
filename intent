import json
import re
from datetime import datetime
from typing import Dict, Any, List, Optional, Literal, Tuple
from google import genai
from google.genai import types
from pydantic import BaseModel, Field, field_validator, model_validator
from concurrent.futures import ThreadPoolExecutor, as_completed
import hashlib


QUERY_EXPANSION_PROMPT = """
You are an expert medical AI assistant specializing in clinical query expansion.

TASK: Expand the user's query into a comprehensive, detailed clinical description.

INSTRUCTIONS:
1. Expand ALL medical abbreviations to full terms (e.g., HTN → Hypertension, DM → Diabetes Mellitus, SOB → Shortness of Breath)
2. Clarify vague medical terms with specific clinical language
3. Add relevant medical context based on standard clinical practice
4. Identify implicit clinical concepts that should be explicit
5. DO NOT add assumptions beyond reasonable clinical interpretation
6. DO NOT include action verbs like "analyze", "review", "check" unless in original query
7. DO NOT hallucinate information not implied by the query
8. Maintain the original query's intent and scope
9.Make sure the Temporal accept is relevant to the Query context

EXAMPLES:
- "Pt with DM" → "Patient with Diabetes Mellitus"
- "Check vitals" → "Vital signs measurement including blood pressure, heart rate, temperature, respiratory rate, oxygen saturation"
- "Family hx of heart disease" → "Cardiovascular disease in family including coronary artery disease, myocardial infarction, heart failure"
- "SOB on exertion" → "Shortness of breath on exertion"

Return ONLY valid JSON (no markdown, no explanation):
{{
  "expanded_query": "comprehensive expanded clinical description",
  "abbreviations_expanded": ["list of abbreviations that were expanded"] 
}}

User Input: {query}
"""

INTENT_EXTRACTION_PROMPT ="""
You are a clinical intent extraction engine for medical document retrieval.

====================================================
CLINICAL VALIDATION
====================================================

Return this ONLY if query is non-clinical:
{{"is_clinical": false, "reason": "Query is not clinical in nature", "intents": []}}

====================================================
CORE PRINCIPLES
====================================================

**Extraction Philosophy:**
When someone requests clinical information, extract everything needed to fully understand, act upon, or make decisions about that information safely and effectively.

**Guiding Questions:**
1. What is being requested?
2. What contextual information is inseparable from this concept?
3. What would be incomplete or unsafe without?
4. How is this information naturally organized?

**Inseparability Concept:**
Some information types are inherently connected for safety, understanding, or completeness. When extracting one, consider whether the other is contextually necessary.

====================================================
INTENT GENERATION
====================================================

**Analyze the expanded query and identify distinct clinical intents.**

Each intent represents a clinically independent concept that could be documented or understood separately.

Generate as many intents as the expanded query contains. Let the content guide the count.

====================================================
INTENT STRUCTURE
====================================================

For each intent:

1. **intent_title** - What is this about?
2. **description** - What does this represent and why does it matter?
3. **nature** - What is the primary informational purpose? (Format: [Context] / [Purpose])
4. **sub_natures[]** - What are the distinct dimensions of this information?
5. **final_queries[]** - How would this appear in clinical documents?

====================================================
SUB_NATURE DECOMPOSITION
====================================================

**Core Question: "What are the meaningful aspects of this clinical concept?"**

Structure:
{{
  "category_path": "Broad >> Specific >> Detail",
  "atomic_concepts": ["terminal1", "terminal2"]
}}

**CATEGORY_PATH:**
Think of this as organizing information from general to specific. Each level adds meaningful distinction. Use " >> " as the separator.

Consider: "How would I navigate to this information?"

**ATOMIC_CONCEPTS:**
These are the actual data points - the most specific, granular elements at the end of the navigation path.

Consider: "What are the specific pieces of information needed?"

Include all specific details mentioned: exact values, names, dates, measurements, descriptors.

**Key Understanding:**
- category_path = How to get there (the folders)
- atomic_concepts = What's there (the files - be specific)

**Dimension Identification:**
Consider: "What different types of information exist for this concept?"
- Names and identifiers?
- Measurements and quantities?
- Time-related information?
- Location information?
- Characteristics and qualities?
- Relationships and connections?
- Safety-related information?
- People involved?
- Current state or status?
- Surrounding circumstances?

Extract the dimensions that are present and relevant.

**Grouping Logic:**
If multiple pieces of information answer the same type of question, group them in one sub_nature. Build depth in the category_path rather than creating many shallow sub_natures.

====================================================
FINAL_QUERIES: ATOMIC SPECIFICITY
====================================================

**Purpose:**
Generate concise, atomic-level queries that map to precise clinical concepts without generating excessive CUIs.

**Core Insight:**
Long verbose queries generate too many CUIs. Short atomic queries target specific concepts.

Consider the difference:
-  "metformin 500mg twice daily for diabetes management" → generates 10+ CUIs, which is not required
- ✓ "metformin 500mg" → generates 2-3 focused CUIs
- ✓ "twice daily dosing" → generates 1-2 CUIs

**Atomic Query Principle:**
Each query should represent ONE atomic clinical concept or a tight pairing of inseparable concepts.

Think: "What's the smallest meaningful unit?"
- A specific medication + dose
- A specific measurement + value
- A specific condition + severity
- A specific procedure + site

**Generation Approach:**

Extract atomic_concepts directly as queries. Keep them SHORT and PRECISE.

**Guiding Questions:**
- What's the core medical term?
- Is there ONE essential modifier (dose, site, severity)?
- Can this be made shorter while staying meaningful?
- Will this generate a focused set of CUIs?

**Query Characteristics:**
- 2-4 words maximum
- One clinical concept per query
- Include only essential modifiers
- Use standard medical terminology
- Each query → 1-3 CUIs ideally

**Natural Reasoning:**
- Shorter = fewer CUIs = more precise matching
- Atomic = focused = findable
- Multiple short queries > one long query
- Coverage through quantity, not length

**Coverage:**
Generate multiple atomic queries per intent. Each atomic_concept should appear in at least one query, but keep each query short and focused.

====================================================
REASONING FRAMEWORK
====================================================

**Before finalizing, consider:**

On Completeness:
- Have all distinct intents in the expanded query been identified?
- For each intent, have all relevant dimensions been extracted?
- Is there information that's inseparable from what was extracted?

On Specificity:
- Are atomic_concepts as specific as possible?
- Have actual values been included, not just categories?
- Are queries detailed enough to be useful?

On Structure:
- Does each sub_nature represent a different type of information?
- Are atomic_concepts truly the most granular elements?
- Is information properly organized?

On Utility:
- Would someone find what they need with these queries?
- Are the queries realistic for clinical documentation?
- Do the queries cover all the important atomic_concepts?

User Input: {expanded_query}
Timestamp: {timestamp}
"""


# SCHEMA

class PipelineInput(BaseModel):
    query: str
    verbose: bool = False

    @field_validator('query', mode='before')
    @classmethod
    def ensure_string(cls, v):
        return str(v).strip()



class QueryExpansionOutput(BaseModel):
    expanded_query: str
    abbreviations_expanded: List[str] = Field(default_factory=list)


class SubNature(BaseModel):
    category_path: str
    atomic_concepts: List[str]
    
    @field_validator('category_path')
    @classmethod
    def normalize_separator(cls, v: str) -> str:
        if '>>' not in v:
            raise ValueError("category_path must use '>>' as separator")
        return re.sub(r'\s*>>\s*', ' >> ', v).strip()

class Intent(BaseModel):
    intent_title: str
    description: str
    nature: str
    sub_natures: List[SubNature]
    final_queries: List[str]


class IntentWithoutQueries(BaseModel):    
    intent_title: str
    description: str
    nature: str
    sub_natures: List[SubNature]


class IntentExtractionOutput(BaseModel):
    is_clinical: bool
    reason: Optional[str] = None
    original_query: str
    expanded_query: str
    total_intents_detected: int
    intents: List[Intent] = Field(default_factory=list)
    
    @model_validator(mode='after')
    def fix_intent_count(self) -> 'IntentExtractionOutput':
        actual = len(self.intents)
        if self.total_intents_detected != actual:
            self.total_intents_detected = actual
        return self


# Output schemas
class IntentSummaryItem(BaseModel):
    intent_title: str
    description: str


class Format_IntentExtraction(BaseModel):
    
    user_query: str
    intents: List[IntentSummaryItem]
    is_clinical: bool
    rejected_reason: Optional[str] = None
    timestamp: str


class Format_FinalQueries(BaseModel):    
    user_query: str
    final_queries: List[str]
    total_queries: int
    is_clinical: bool
    rejected_reason: Optional[str] = None
    timestamp: str


class Format_NatureBreakdown(BaseModel):    
    is_clinical: bool
    reason: Optional[str] = None
    original_query: str
    # expanded_query: str
    total_intents_detected: int
    intents: List[IntentWithoutQueries]
    timestamp: str



# EXTRACTION

class ExtractionResult:    
    def __init__(self, 
                 original_query: str,
                 expansion: QueryExpansionOutput,
                 intents: IntentExtractionOutput,
                 processing_time: float):
        self.original_query = original_query
        self.expansion = expansion
        self.intents = intents
        self.processing_time = processing_time
        self.timestamp = datetime.utcnow().isoformat()
    
    def to_intent_extraction(self) -> Dict[str, Any]:
        
        items = [
            IntentSummaryItem(
                intent_title=i.intent_title,
                description=i.description
            ) for i in self.intents.intents
        ]
        
        result = Format_IntentExtraction(
            user_query=self.original_query,
            intents=items,
            is_clinical=self.intents.is_clinical,
            rejected_reason=self.intents.reason,
            timestamp=self.timestamp
        )
        return result.model_dump()
    
    def to_final_queries(self) -> Dict[str, Any]:        
        queries = [q for intent in self.intents.intents for q in intent.final_queries]
        
        result = Format_FinalQueries(
            user_query=self.original_query,
            final_queries=queries,
            total_queries=len(queries),
            is_clinical=self.intents.is_clinical,
            rejected_reason=self.intents.reason,
            timestamp=self.timestamp
        )
        return result.model_dump()
    
    def to_nature_breakdown(self) -> Dict[str, Any]:        
        intents_no_queries = [
            IntentWithoutQueries(
                intent_title=i.intent_title,
                description=i.description,
                nature=i.nature,
                sub_natures=i.sub_natures
            ) for i in self.intents.intents
        ]
        
        result = Format_NatureBreakdown(
            is_clinical=self.intents.is_clinical,
            reason=self.intents.reason,
            original_query=self.intents.original_query,
            expanded_query=self.intents.expanded_query,
            total_intents_detected=self.intents.total_intents_detected,
            intents=intents_no_queries,
            timestamp=self.timestamp
        )
        return result.model_dump()
    
    def to_all_formats(self) -> Dict[str, Dict[str, Any]]:        
        return {
            "intent_extraction": self.to_intent_extraction(),
            "final_queries": self.to_final_queries(),
            "nature_breakdown": self.to_nature_breakdown()
        }



# PIPELINE CLASS


class ContextualIntentPipeline:
    
    def __init__(self, project: str, location: str = LOCATION, model: str = MODEL_VERSION):       
        self.client = genai.Client(
            vertexai=True,
            project=project,
            location=location
        )
        
        self.project = project
        self.location = location
        self.model_name = model
        
     
        
    def _extract_json(self, response) -> Dict[str, Any]:
       
        if hasattr(response, 'text'):
            text = response.text
        elif hasattr(response, 'candidates') and response.candidates:
            text = response.candidates[0].content.parts[0].text
        else:
            text = str(response)
        
        text = re.sub(r'```json\s*', '', text)
        text = re.sub(r'```\s*', '', text)
        text = text.strip()
        
        try:
            return json.loads(text)
        except:
            pass
        
        json_patterns = [
            (r'\{.*?\}', re.DOTALL),
            (r'\[.*?\]', re.DOTALL),
        ]
        
        for pattern, flags in json_patterns:
            matches = list(re.finditer(pattern, text, flags))
            matches.sort(key=lambda m: len(m.group(0)), reverse=True)
            
            for match in matches:
                try:
                    return json.loads(match.group(0))
                except:
                    continue
        
        raise ValueError(f"Could not parse JSON from response: {text[:500]}...")
    
    def _call_model(self, prompt: str, response_schema: type[BaseModel],
                    context_query: str = "") -> BaseModel:        
        try:
            config = types.GenerateContentConfig(
                temperature=0.0,
                top_p=0.2,
                seed=34,
                max_output_tokens=8096,
                response_mime_type="application/json",
                response_schema=response_schema
            )
            
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=prompt,
                config=config
            )
            
            data = self._extract_json(response)
            return response_schema.model_validate(data)
            
        except Exception as e:
            print(f"Model error: {e}")
            
            if response_schema == QueryExpansionOutput:
                return QueryExpansionOutput(
                    expanded_query=context_query if context_query else "",
                    abbreviations_expanded=[]
                )
            else:
                return IntentExtractionOutput(
                    is_clinical=False,
                    reason=f"Processing error: {str(e)}",
                    original_query=context_query if context_query else "",
                    expanded_query=context_query if context_query else "",
                    total_intents_detected=0,
                    intents=[]
                )
    
    def expand_query(self, query: str) -> QueryExpansionOutput:
        """Step 1: Expand abbreviations and add clinical context"""
        prompt = QUERY_EXPANSION_PROMPT.format(query=query)
        return self._call_model(prompt, QueryExpansionOutput, query)
    
    def extract_intents(self, original_query: str, expanded_query: str) -> IntentExtractionOutput:
        """Step 2: Extract clinical intents with sub-natures"""
        prompt = INTENT_EXTRACTION_PROMPT.format(
            original_query=original_query,
            expanded_query=expanded_query,
            timestamp=datetime.utcnow().isoformat()
        )
        return self._call_model(prompt, IntentExtractionOutput, original_query)
    
    def extract(self, query: str, verbose: bool = False) -> ExtractionResult:       
        if not query or not query.strip():
            raise ValueError("Empty query provided")
        
        start_time = datetime.utcnow()
        
        # Step 1: Expand query
        expansion = self.expand_query(query)
        
        # Step 2: Extract intents
        intents = self.extract_intents(query, expansion.expanded_query)
        
        processing_time = (datetime.utcnow() - start_time).total_seconds()
        
        if verbose:
            print(f"Original Query: {query}")
            print(f"Expanded Query: {expansion.expanded_query}")
            
            if intents.is_clinical:
                total_queries = sum(len(i.final_queries) for i in intents.intents)
                total_sub_natures = sum(len(i.sub_natures) for i in intents.intents)
                print(f"Status: Clinical")
                print(f"Intents: {intents.total_intents_detected} | Sub-natures: {total_sub_natures} | Queries: {total_queries}")
            else:
                print(f"Status: Non-clinical")
                print(f"Reason: {intents.reason}")
            
            print(f"Processing Time: {processing_time:.2f}s")
            print()
        
        return ExtractionResult(query, expansion, intents, processing_time)
    
    def run(self, query: str,
            output_format: Literal["intent_extraction", "final_queries", "nature_breakdown"] = "nature_breakdown",
            verbose: bool = False) -> Dict[str, Any]:
        
        try:
            result = self.extract(query, verbose)
            
            if output_format == "intent_extraction":
                return result.to_intent_extraction()
            elif output_format == "final_queries":
                return result.to_final_queries()
            else:
                return result.to_nature_breakdown()
                
        except ValueError as e:
            return {
                "error": str(e),
                "query": query,
                "timestamp": datetime.utcnow().isoformat()
            }
        except Exception as e:
            if verbose:
                print(f"Error: {e}\n")
            return {
                "error": str(e),
                "query": query,
                "timestamp": datetime.utcnow().isoformat()
            }



# UTILITY


def save_json(data: Dict, filename: str):   
    with open(filename, 'w') as f:
        json.dump(data, f, indent=2)
    print(f"{filename}")


def print_results(result: Dict):    
    print(json.dumps(result, indent=2))


def validate_schema(result: Dict, format_type: str) -> Tuple[bool, Optional[str]]:    
    try:
        if format_type == "intent_extraction":
            Format_IntentExtraction.model_validate(result)
        elif format_type == "final_queries":
            Format_FinalQueries.model_validate(result)
        elif format_type == "nature_breakdown":
            Format_NatureBreakdown.model_validate(result)
        else:
            return False, f"Unknown format type: {format_type}"
        
        return True, None
        
    except Exception as e:
        return False, str(e)


def test_pipeline_consistency(pipeline, query: str):
    """Run the pipeline for a query and save all output formats."""
    result = pipeline.extract(query, verbose=True)
    all_formats = result.to_all_formats()
    
    for fmt, data in all_formats.items():
        filename = f"{fmt}.json"
        save_json(data, filename)
        # Ignore unused return values
        _, _ = validate_schema(data, fmt)      


def run_single_query(pipeline, query: str, idx: int):
    """Run the pipeline for a single query, save outputs, and return summary."""
    result = pipeline.extract(query, verbose=True)
    all_formats = result.to_all_formats()
    
    prefix = f"query{idx}"

    save_json(all_formats["intent_extraction"], f"{prefix}_intent_extraction.json")
    save_json(all_formats["final_queries"], f"{prefix}_final_queries.json")
    save_json(all_formats["nature_breakdown"], f"{prefix}_nature_breakdown.json")
    print("-" * 60)

    return {
        "query": query,
        "status": "completed",
        "files": [
            f"{prefix}_intent_extraction.json",
            f"{prefix}_final_queries.json",
            f"{prefix}_nature_breakdown.json",
        ]
    }


if __name__ == "__main__":
    pipeline = ContextualIntentPipeline(
        project=PROJECT_ID,
        location=LOCATION,
        model=MODEL_VERSION
    )

    test_queries = [
        "HAVE YOU RECEIVED ANY TREATMENT FOR YOUR CANCER?"
    ]

    results = []

    # Parallel execution
    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = {
            executor.submit(run_single_query, pipeline, query, idx): query
            for idx, query in enumerate(test_queries, 1)
        }

        for future in as_completed(futures):
            results.append(future.result())
