"""
MODULE 2: CUI CLUSTERING & SEMANTIC TOPIC DISCOVERY
USING BIGQUERY EMBEDDINGS (NO FREQUENCY)
"""

import time
import numpy as np
import pandas as pd
from typing import List, Dict, Optional
from dataclasses import dataclass
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from google.cloud import bigquery

# ══════════════════════════════════════════════════════════════════
# CONFIGURATION
# ══════════════════════════════════════════════════════════════════

DEFAULT_N_TOPICS = 10
MIN_CUIS_PER_TOPIC = 1
TOP_K_LABELS = 5

# ══════════════════════════════════════════════════════════════════
# UTILS
# ══════════════════════════════════════════════════════════════════

def normalize(v: np.ndarray) -> np.ndarray:
    return v / (np.linalg.norm(v) + 1e-10)

# ══════════════════════════════════════════════════════════════════
# DATA STRUCTURES
# ══════════════════════════════════════════════════════════════════

@dataclass
class CUISet:
    set_id: Optional[str]
    cuis: List[str]

@dataclass
class Topic:
    topic_id: int
    primary_label: str
    representative_cuis: List[str]
    representative_definitions: List[str]
    cui_set_ids: List[str]
    set_count: int
    all_cuis: List[str]

@dataclass
class TopicResult:
    topics: List[Topic]
    set_to_topic: Dict[str, int]
    n_topics: int
    silhouette_score: Optional[float]
    processing_time: float

# ══════════════════════════════════════════════════════════════════
# BIGQUERY EMBEDDING + DEFINITION STORE
# ══════════════════════════════════════════════════════════════════

class BigQueryEmbeddingStore:
    """Fetch CUI embeddings and definitions from BigQuery"""

    def __init__(self, project_id: str, dataset_id: str, table_name: str):
        self.client = bigquery.Client(project=project_id)
        self.project_id = project_id
        self.dataset_id = dataset_id
        self.table_name = table_name

    def get_batch(self, cuis: List[str]) -> Dict[str, Dict]:
        if not cuis:
            return {}

        query = f"""
        SELECT CUI, Embedding, Definition
        FROM `{self.project_id}.{self.dataset_id}.{self.table_name}`
        WHERE CUI IN UNNEST(@cuis)
        """

        job_config = bigquery.QueryJobConfig(
            query_parameters=[
                bigquery.ArrayQueryParameter("cuis", "STRING", cuis)
            ]
        )

        df = self.client.query(query, job_config=job_config).to_dataframe()

        return {
            row["CUI"]: {
                "embedding": np.array(row["Embedding"], dtype=np.float32),
                "definition": row["Definition"]
            }
            for _, row in df.iterrows()
        }

# ══════════════════════════════════════════════════════════════════
# CUI SET EMBEDDER
# ══════════════════════════════════════════════════════════════════

class CUISetEmbedder:
    def __init__(self, store: BigQueryEmbeddingStore):
        self.store = store

    def embed(self, cui_sets: List[CUISet]) -> Dict[str, np.ndarray]:
        embeddings = {}

        for s in cui_sets:
            cui_data = self.store.get_batch(s.cuis)
            vecs = [v["embedding"] for v in cui_data.values()]

            embeddings[s.set_id or "set0"] = (
                normalize(np.mean(vecs, axis=0))
                if vecs else np.zeros(768, dtype=np.float32)
            )

        return embeddings

# ══════════════════════════════════════════════════════════════════
# MAIN TOPIC MODELER
# ══════════════════════════════════════════════════════════════════

class CUITopicModeler:
    def __init__(self, embedding_store: BigQueryEmbeddingStore):
        self.embedding_store = embedding_store
        self.embedder = CUISetEmbedder(embedding_store)

    def discover_topics(self, cui_sets: List[CUISet], n_topics: int) -> TopicResult:
        start_time = time.time()

        # === 1. Embed CUI sets (BigQuery) ===
        set_embeddings = self.embedder.embed(cui_sets)
        X = np.stack(list(set_embeddings.values()))
        set_ids = list(set_embeddings.keys())

        # === 2. Cluster ===
        kmeans = KMeans(
            n_clusters=min(n_topics, len(X)),
            random_state=42,
            n_init=10
        )
        labels = kmeans.fit_predict(X)

        # === 3. Fetch ALL CUI embeddings + definitions from BigQuery ===
        all_cuis = list({c for s in cui_sets for c in s.cuis})
        cui_data = self.embedding_store.get_batch(all_cuis)

        cui_ids = list(cui_data.keys())
        cui_embeddings = np.stack([normalize(v["embedding"]) for v in cui_data.values()])
        cui_definitions = {k: v["definition"] for k, v in cui_data.items()}

        topics = []

        for tid in sorted(set(labels)):
            idxs = [i for i, l in enumerate(labels) if l == tid]
            cluster_sets = [cui_sets[i] for i in idxs]

            if len(cluster_sets) < MIN_CUIS_PER_TOPIC:
                continue

            # === 4. Topic centroid ===
            centroid = normalize(np.mean(X[idxs], axis=0))

            # === 5. Semantic topic labeling (NO FREQUENCY) ===
            sims = np.dot(cui_embeddings, centroid)
            top_idx = sims.argsort()[::-1][:TOP_K_LABELS]

            rep_cuis = [cui_ids[i] for i in top_idx]
            rep_defs = [cui_definitions[c] for c in rep_cuis]
            primary_label = " + ".join(rep_cuis[:3])

            topics.append(
                Topic(
                    topic_id=tid,
                    primary_label=primary_label,
                    representative_cuis=rep_cuis,
                    representative_definitions=rep_defs,
                    cui_set_ids=[set_ids[i] for i in idxs],
                    set_count=len(cluster_sets),
                    all_cuis=list({c for s in cluster_sets for c in s.cuis})
                )
            )

        sil = (
            float(silhouette_score(X, labels, metric="cosine"))
            if len(set(labels)) > 1
            else None
        )

        return TopicResult(
            topics=topics,
            set_to_topic=dict(zip(set_ids, labels)),
            n_topics=len(topics),
            silhouette_score=sil,
            processing_time=time.time() - start_time
        )

# ══════════════════════════════════════════════════════════════════
# ENTRY FUNCTION
# ══════════════════════════════════════════════════════════════════

def run_module2(
    df_reduction: pd.DataFrame,
    project_id: str,
    dataset_id: str,
    embedding_table: str,
    n_topics: int = DEFAULT_N_TOPICS
) -> TopicResult:
    """
    Run Module 2: CUI clustering & semantic topic discovery
    """

    if "cui" not in df_reduction.columns:
        raise ValueError("DataFrame must have a 'cui' column")

    if len(df_reduction) != 1:
        raise ValueError("Expected single-row DataFrame")

    cuis = df_reduction.iloc[0]["cui"]

    if not isinstance(cuis, list) or not cuis:
        raise ValueError("'cui' must be a non-empty list")

    cui_sets = [CUISet(set_id=c, cuis=[c]) for c in cuis]

    store = BigQueryEmbeddingStore(
        project_id=project_id,
        dataset_id=dataset_id,
        table_name=embedding_table
    )

    modeler = CUITopicModeler(store)

    return modeler.discover_topics(cui_sets, n_topics=n_topics)

# ══════════════════════════════════════════════════════════════════
# EXAMPLE EXECUTION
# ══════════════════════════════════════════════════════════════════

if __name__ == "__main__":
    result = run_module2(
        df_reduction=df_module2,
        project_id=project_id,
        dataset_id=dataset,
        embedding_table=embedding_table,
        n_topics=DEFAULT_N_TOPICS
    )

    print(f"\nDiscovered {len(result.topics)} topics")
    print(f"Silhouette score: {result.silhouette_score}\n")

    for t in result.topics:
        print(f"Topic {t.topic_id}")
        print(f" Label CUIs: {t.primary_label}")
        print(" Definitions:")
        for d in t.representative_definitions:
            print(f"  - {d}")
        print("-" * 60)
