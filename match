"""
MATCHING LOGIC: Match Query CUIs to Document Topic CUIs
=======================================================
INPUT:  LHS output (query CUIs + graph + embeddings)
        RHS output (topic CUIs + graph + embeddings)
OUTPUT: Matched CUIs with confidence scores + method breakdown

3-Tier Matching Strategy:
1. Direct matches (confidence: 1.0)
2. Ancestor matches with hybrid scoring (confidence: 0.5-0.9)
3. Embedding matches (confidence: 0.7+)
"""

import pickle
import numpy as np
import networkx as nx
import pandas as pd
from typing import Dict, List, Tuple, Set, Optional
from sklearn.metrics.pairwise import cosine_similarity
import json

# =============================================================================
# CONFIGURATION
# =============================================================================

CONFIG = {
    # Input files from LHS and RHS
    'lhs_graph': 'lhs_reduced_graph.pkl',
    'lhs_embeddings': 'lhs_embeddings.pkl',
    'rhs_graph': 'rhs_topic_graph.pkl',
    'rhs_embeddings': 'rhs_embeddings.pkl',
    
    # Output files
    'output_csv': 'cui_matches.csv',
    'output_json': 'cui_stats.json',
    'output_detailed': 'cui_matches_detailed.json',
}

# =============================================================================
# CUI MATCHER
# =============================================================================

class CUIMapper:
    """
    3-Tier CUI Matching Strategy:
    1. Direct matches
    2. Ancestor matches (with hybrid scoring)
    3. Embedding matches (conditional)
    """
    
    def __init__(
        self,
        reduced_graph: nx.DiGraph,
        reduced_embeddings: Dict[str, np.ndarray],
        topic_graph: nx.DiGraph,
        topic_embeddings: Dict[str, np.ndarray]
    ):
        self.reduced_graph = reduced_graph
        self.reduced_embeddings = reduced_embeddings
        self.topic_graph = topic_graph
        self.topic_embeddings = topic_embeddings
        
        self.reduced_cuis = set(reduced_graph.nodes())
        self.topic_cuis = set(topic_graph.nodes())
        
        print(f"\n{'='*80}")
        print("CUI MATCHER INITIALIZED")
        print(f"{'='*80}")
        print(f"  Query CUIs (LHS):    {len(self.reduced_cuis):,}")
        print(f"  Topic CUIs (RHS):    {len(self.topic_cuis):,}")
        print(f"  Query embeddings:    {len(self.reduced_embeddings):,}")
        print(f"  Topic embeddings:    {len(self.topic_embeddings):,}")
        print(f"{'='*80}\n")
    
    def match_all(
        self,
        ancestor_max_depth: int = 5,
        use_hybrid_scoring: bool = True,
        embedding_threshold: float = 0.7,
        skip_embedding_if_ratio_high: float = 0.9
    ) -> Tuple[pd.DataFrame, Dict]:
        """
        Execute complete 3-tier matching pipeline
        
        Returns:
            (results_df, stats_dict)
        """
        print(f"\n{'='*80}")
        print("STARTING 3-TIER MATCHING PIPELINE")
        print(f"{'='*80}")
        print(f"Total topic CUIs to match: {len(self.topic_cuis):,}")
        print(f"{'='*80}\n")
        
        all_results = []
        matched_cuis = set()
        
        # =====================================================================
        # TIER 1: Direct Matches
        # =====================================================================
        print(f"{'='*80}")
        print("TIER 1: DIRECT MATCHING")
        print(f"{'='*80}")
        
        direct_matches = []
        for topic_cui in self.topic_cuis:
            if topic_cui in self.reduced_cuis:
                direct_matches.append({
                    'topic_cui': topic_cui,
                    'reduced_cui': topic_cui,
                    'method': 'direct',
                    'confidence': 1.0,
                    'similarity': 1.0,
                    'hybrid_score': 1.0
                })
        
        direct_df = pd.DataFrame(direct_matches)
        all_results.append(direct_df)
        matched_cuis.update(set(direct_df['topic_cui']) if len(direct_df) > 0 else set())
        
        print(f"‚úì Direct matches found: {len(direct_df):,}")
        print(f"  Remaining: {len(self.topic_cuis - matched_cuis):,} CUIs\n")
        
        # =====================================================================
        # TIER 2: Ancestor Matches
        # =====================================================================
        unmatched_after_direct = self.topic_cuis - matched_cuis
        
        print(f"{'='*80}")
        print("TIER 2: ANCESTOR MATCHING")
        print(f"{'='*80}")
        print(f"Remaining CUIs: {len(unmatched_after_direct):,}")
        
        ancestor_matches = []
        for topic_cui in unmatched_after_direct:
            ancestor_info = self._get_ancestors(topic_cui, max_depth=ancestor_max_depth)
            matching_ancestors = set(ancestor_info.keys()) & self.reduced_cuis
            
            if not matching_ancestors:
                continue
            
            if use_hybrid_scoring and topic_cui in self.topic_embeddings:
                # Hybrid scoring: ancestor depth + embedding similarity
                topic_emb = self.topic_embeddings[topic_cui]
                best_score = -1
                best_ancestor = None
                best_info = None
                
                for anc in matching_ancestors:
                    depth, path = ancestor_info[anc]
                    
                    emb_sim = None
                    if anc in self.reduced_embeddings:
                        anc_emb = self.reduced_embeddings[anc]
                        emb_sim = float(cosine_similarity([topic_emb], [anc_emb])[0][0])
                    
                    hybrid_score = self._compute_hybrid_score(depth, emb_sim)
                    
                    if hybrid_score > best_score:
                        best_score = hybrid_score
                        best_ancestor = anc
                        best_info = (depth, path, emb_sim, hybrid_score)
                
                if best_ancestor:
                    depth, path, emb_sim, hybrid_score = best_info
                    confidence = max(0.5, 1.0 - (depth * 0.1))
                    
                    ancestor_matches.append({
                        'topic_cui': topic_cui,
                        'reduced_cui': best_ancestor,
                        'method': 'ancestor',
                        'confidence': confidence,
                        'similarity': emb_sim,
                        'ancestor_depth': depth,
                        'ancestor_path': '‚Üí'.join(path),
                        'hybrid_score': hybrid_score,
                        'num_candidates': len(matching_ancestors)
                    })
            else:
                # Simple closest ancestor
                best_ancestor = min(matching_ancestors, key=lambda a: (ancestor_info[a][0], a))
                depth, path = ancestor_info[best_ancestor]
                confidence = max(0.5, 1.0 - (depth * 0.1))
                
                ancestor_matches.append({
                    'topic_cui': topic_cui,
                    'reduced_cui': best_ancestor,
                    'method': 'ancestor',
                    'confidence': confidence,
                    'ancestor_depth': depth,
                    'ancestor_path': '‚Üí'.join(path),
                    'num_candidates': len(matching_ancestors)
                })
        
        ancestor_df = pd.DataFrame(ancestor_matches)
        all_results.append(ancestor_df)
        matched_cuis.update(set(ancestor_df['topic_cui']) if len(ancestor_df) > 0 else set())
        
        print(f"‚úì Ancestor matches found: {len(ancestor_df):,}")
        print(f"  Remaining: {len(self.topic_cuis - matched_cuis):,} CUIs\n")
        
        # =====================================================================
        # TIER 3: Embedding Matches (Conditional)
        # =====================================================================
        unmatched_after_ancestor = self.topic_cuis - matched_cuis
        current_match_rate = len(matched_cuis) / len(self.topic_cuis) if len(self.topic_cuis) > 0 else 0
        
        print(f"Current match rate: {current_match_rate*100:.1f}%")
        
        if len(unmatched_after_ancestor) > 0:
            if current_match_rate >= skip_embedding_if_ratio_high:
                print(f"Skipping embedding step (match rate {current_match_rate*100:.1f}% >= {skip_embedding_if_ratio_high*100:.1f}%)\n")
                embedding_df = pd.DataFrame()
            else:
                print(f"\n{'='*80}")
                print("TIER 3: EMBEDDING MATCHING")
                print(f"{'='*80}")
                print(f"Remaining CUIs: {len(unmatched_after_ancestor):,}")
                
                embedding_matches = self._embedding_match(
                    unmatched_after_ancestor,
                    similarity_threshold=embedding_threshold
                )
                
                embedding_df = pd.DataFrame(embedding_matches)
                all_results.append(embedding_df)
                matched_cuis.update(set(embedding_df['topic_cui']) if len(embedding_df) > 0 else set())
                
                print(f"‚úì Embedding matches found: {len(embedding_df):,}\n")
        else:
            print("No unmatched CUIs - skipping embedding step\n")
            embedding_df = pd.DataFrame()
        
        # =====================================================================
        # Combine Results and Generate Statistics
        # =====================================================================
        results_df = pd.concat(all_results, ignore_index=True) if all_results else pd.DataFrame()
        unmatched_cuis = self.topic_cuis - matched_cuis
        
        stats = {
            'total_topic_cuis': len(self.topic_cuis),
            'total_query_cuis': len(self.reduced_cuis),
            'total_matched': len(matched_cuis),
            'total_unmatched': len(unmatched_cuis),
            'match_rate': len(matched_cuis) / len(self.topic_cuis) if len(self.topic_cuis) > 0 else 0,
            'by_method': {
                'direct': len(direct_df),
                'ancestor': len(ancestor_df),
                'embedding': len(embedding_df)
            },
            'avg_confidence': float(results_df['confidence'].mean()) if len(results_df) > 0 else 0,
            'avg_hybrid_score': float(results_df['hybrid_score'].mean()) if 'hybrid_score' in results_df.columns and len(results_df) > 0 else 0
        }
        
        # Print summary
        self._print_summary(stats)
        
        return results_df, stats
    
    def _get_ancestors(self, cui: str, max_depth: int = 5) -> Dict[str, Tuple[int, List[str]]]:
        """Get all ancestors with their depths and paths"""
        if cui not in self.topic_graph:
            return {}
        
        ancestor_info = {}
        visited = {cui}
        current_level = {cui: (0, [cui])}
        
        for depth in range(1, max_depth + 1):
            next_level = {}
            for node, (_, path) in current_level.items():
                parents = set(self.topic_graph.predecessors(node))
                for parent in parents:
                    if parent not in visited:
                        new_path = path + [parent]
                        ancestor_info[parent] = (depth, new_path)
                        next_level[parent] = (depth, new_path)
                        visited.add(parent)
            if not next_level:
                break
            current_level = next_level
        
        return ancestor_info
    
    def _compute_hybrid_score(
        self,
        ancestor_depth: Optional[int] = None,
        embedding_similarity: Optional[float] = None,
        ancestor_weight: float = 0.4,
        embedding_weight: float = 0.6
    ) -> float:
        """Compute hybrid score"""
        if ancestor_depth is None and embedding_similarity is None:
            return 0.0
        
        ancestor_score = np.exp(-ancestor_depth / 3.0) if ancestor_depth is not None else 0.0
        embedding_score = embedding_similarity if embedding_similarity is not None else 0.0
        
        if ancestor_depth is not None and embedding_similarity is not None:
            return ancestor_weight * ancestor_score + embedding_weight * embedding_score
        elif ancestor_depth is not None:
            return ancestor_score
        else:
            return embedding_score
    
    def _embedding_match(
        self,
        unmatched_cuis: Set[str],
        similarity_threshold: float = 0.7
    ) -> List[Dict]:
        """Find embedding-based matches"""
        topic_cuis_with_emb = [cui for cui in unmatched_cuis if cui in self.topic_embeddings]
        
        if not topic_cuis_with_emb:
            return []
        
        reduced_cuis_with_emb = [cui for cui in self.reduced_cuis if cui in self.reduced_embeddings]
        
        if not reduced_cuis_with_emb:
            return []
        
        reduced_emb_matrix = np.array([self.reduced_embeddings[cui] for cui in reduced_cuis_with_emb])
        
        matches = []
        for topic_cui in topic_cuis_with_emb:
            topic_emb = self.topic_embeddings[topic_cui]
            similarities = cosine_similarity([topic_emb], reduced_emb_matrix)[0]
            best_idx = np.argmax(similarities)
            best_score = similarities[best_idx]
            
            if best_score >= similarity_threshold:
                matches.append({
                    'topic_cui': topic_cui,
                    'reduced_cui': reduced_cuis_with_emb[best_idx],
                    'method': 'embedding',
                    'confidence': float(best_score),
                    'similarity': float(best_score),
                    'hybrid_score': float(best_score)
                })
        
        return matches
    
    def _print_summary(self, stats: Dict):
        """Print final summary"""
        print(f"\n{'='*80}")
        print("MATCHING SUMMARY")
        print(f"{'='*80}")
        print(f"Topic CUIs (RHS):    {stats['total_topic_cuis']:,}")
        print(f"Query CUIs (LHS):    {stats['total_query_cuis']:,}")
        print(f"Total matched:       {stats['total_matched']:,} ({stats['match_rate']*100:.1f}%)")
        print(f"Total unmatched:     {stats['total_unmatched']:,}")
        
        print(f"\nBreakdown by method:")
        for method, count in stats['by_method'].items():
            pct = (count / stats['total_matched'] * 100) if stats['total_matched'] > 0 else 0
            print(f"  {method:12s}: {count:6,} ({pct:5.1f}%)")
        
        print(f"\nQuality metrics:")
        print(f"  Avg confidence:   {stats['avg_confidence']:.3f}")
        print(f"  Avg hybrid score: {stats['avg_hybrid_score']:.3f}")
        print(f"{'='*80}\n")

# =============================================================================
# MAIN EXECUTION
# =============================================================================

def run_matching(config: Dict = CONFIG):
    """
    Execute matching pipeline
    
    Loads LHS and RHS outputs, runs 3-tier matching, saves results
    """
    print("\n" + "‚ïî"+"="*78+"‚ïó")
    print("‚ïë" + " "*25 + "CUI MATCHING PIPELINE" + " "*32 + "‚ïë")
    print("‚ïö"+"="*78+"‚ïù")
    
    # Load LHS outputs
    print("\n[1/4] Loading LEFT HAND SIDE outputs...")
    with open(config['lhs_graph'], 'rb') as f:
        lhs_graph = pickle.load(f)
    with open(config['lhs_embeddings'], 'rb') as f:
        lhs_embeddings = pickle.load(f)
    print(f"      Query graph: {lhs_graph.number_of_nodes():,} nodes, {lhs_graph.number_of_edges():,} edges")
    print(f"      Query embeddings: {len(lhs_embeddings):,}")
    
    # Load RHS outputs
    print("\n[2/4] Loading RIGHT HAND SIDE outputs...")
    with open(config['rhs_graph'], 'rb') as f:
        rhs_graph = pickle.load(f)
    with open(config['rhs_embeddings'], 'rb') as f:
        rhs_embeddings = pickle.load(f)
    print(f"      Topic graph: {rhs_graph.number_of_nodes():,} nodes, {rhs_graph.number_of_edges():,} edges")
    print(f"      Topic embeddings: {len(rhs_embeddings):,}")
    
    # Initialize matcher
    print("\n[3/4] Initializing matcher...")
    matcher = CUIMapper(
        reduced_graph=lhs_graph,
        reduced_embeddings=lhs_embeddings,
        topic_graph=rhs_graph,
        topic_embeddings=rhs_embeddings
    )
    
    # Run matching
    print("[4/4] Running 3-tier matching...")
    results_df, stats = matcher.match_all(
        ancestor_max_depth=5,
        use_hybrid_scoring=True,
        embedding_threshold=0.7,
        skip_embedding_if_ratio_high=0.9
    )
    
    # Save results
    print(f"{'='*80}")
    print("SAVING RESULTS")
    print(f"{'='*80}")
    
    # CSV output
    results_df.to_csv(config['output_csv'], index=False)
    print(f"‚úì Saved matches: {config['output_csv']}")
    
    # JSON stats
    with open(config['output_json'], 'w') as f:
        json.dump(stats, f, indent=2)
    print(f"‚úì Saved stats: {config['output_json']}")
    
    # Detailed JSON (with match details)
    detailed_output = {
        'stats': stats,
        'matches': results_df.to_dict('records')
    }
    with open(config['output_detailed'], 'w') as f:
        json.dump(detailed_output, f, indent=2)
    print(f"‚úì Saved detailed: {config['output_detailed']}")
    
    # Display sample results
    print(f"\n{'='*80}")
    print("SAMPLE MATCHES (Top 10)")
    print(f"{'='*80}")
    print(results_df.head(10).to_string(index=False))
    
    print(f"\n{'='*80}")
    print("MATCHING COMPLETE!")
    print(f"{'='*80}\n")
    
    return results_df, stats

# =============================================================================
# USAGE
# =============================================================================

if __name__ == "__main__":
    results, stats = run_matching()
    
    # Additional analysis
    print("\nüìä MATCH DISTRIBUTION:")
    print(results.groupby('method').size())
    
    print("\nüìä CONFIDENCE DISTRIBUTION:")
    print(results['confidence'].describe())
