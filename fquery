INTENT_EXTRACTION_PROMPT = """
You are an expert clinical intent extraction engine.

⚠️ FIRST: Verify this is a CLINICAL query. If NOT related to healthcare/medical/clinical information, return:
{{
  "is_clinical": false,
  "reason": "Query is not clinical in nature",
  "intents": []
}}

TASK: Extract ALL clinical intents and generate specific queries optimized for CUI extraction.

KEY PRINCIPLES:
1. Create DEEP hierarchical taxonomies (3-5 levels minimum)
2. Generate queries from ATOMIC ELEMENTS (deepest level only)
3. Focus on CLINICAL RELEVANCE (10-40 queries per intent)
4. Use CONCISE format (2-5 words per query)

NATURE DETERMINATION - Ask yourself:
- WHEN: Past/Present/Future?
- WHY: Background/Assessment/Decision/Risk/Treatment?
- HOW: Main/Supporting/Baseline?
- WHERE: Patient/Measurement/Documentation/Calculation?

SUB-NATURE STRUCTURE - CRITICAL:
For EACH sub_nature, you MUST provide:
1. **category**: Hierarchical classification (use"""
===============================================================================
CLINICAL INTENT EXTRACTION PIPELINE
===============================================================================
Production-ready system for extracting clinical intents from medical queries
and generating optimized queries for CUI (Concept Unique Identifier) extraction.

Features:
- Deep hierarchical taxonomy generation (3-5 levels)
- Principle-based LLM reasoning (no hardcoded rules)
- Inline clinical validation
- Optimized for speed (15-23 seconds per query)
- Generates 10-40 focused queries per intent

Author: Medical AI Team
Version: 1.0
===============================================================================
"""

import json
import re
from datetime import datetime
from typing import Dict, Any, List
from google.cloud import aiplatform
from vertexai.generative_models import GenerativeModel


# ==============================================================================
# CONFIGURATION
# ==============================================================================

PROJECT_ID = "your-gcp-project-id"  # TODO: Replace with your GCP project ID
LOCATION = "us-central1"
MODEL_NAME = "gemini-2.0-flash-exp"


# ==============================================================================
# LLM PROMPTS
# ==============================================================================

QUERY_EXPANSION_PROMPT = """
You are an expert medical AI assistant specializing in clinical query expansion.

TASK: Expand the user's query into a comprehensive, detailed clinical description.

INSTRUCTIONS:
1. Expand ALL medical abbreviations (HTN → Hypertension, DM → Diabetes Mellitus, SOB → Shortness of Breath)
2. Clarify vague medical terms with specific clinical language
3. Add relevant medical context based on standard clinical practice
4. DO NOT add assumptions beyond reasonable clinical interpretation
5. DO NOT hallucinate information not implied by the query
6. Maintain the original query's intent and scope

Return ONLY valid JSON:
{{
  "expanded_query": "comprehensive expanded clinical description",
  "abbreviations_expanded": ["list of abbreviations expanded"],
  "concepts_added": ["list of medical concepts made explicit"]
}}

User Input: {query}
"""

INTENT_EXTRACTION_PROMPT = """
You are an expert clinical intent extraction engine.

⚠️ FIRST: Verify this is a CLINICAL query. If NOT related to healthcare/medical/clinical information, return:
{{
  "is_clinical": false,
  "reason": "Query is not clinical in nature",
  "intents": []
}}

TASK: Extract ALL clinical intents and generate specific queries optimized for CUI extraction.

KEY PRINCIPLES:
1. Create DEEP hierarchical taxonomies (3-5 levels minimum)
2. Generate queries from ATOMIC ELEMENTS (deepest level only)
3. Focus on CLINICAL RELEVANCE (10-40 queries per intent)
4. Use CONCISE format (2-5 words per query)
5. ALWAYS populate elements AND entities arrays in sub_nature

NATURE DETERMINATION:
Ask: WHEN (Past/Present/Future)? WHY (Purpose)? HOW (Priority)? WHERE (Source)?
Create nature names that capture the essence (e.g., "Clinical History", "Diagnostic Investigation")

SUB-NATURE STRUCTURE:
Each sub_nature MUST have:
- category: "Level2 >> Level3 >> Level4" (hierarchical path)
- elements: [atomic clinical concepts at deepest level]
- entities: [medical entity types for ontology mapping]

QUERY GENERATION:
- Extract atomic elements from DEEPEST taxonomy level only
- Generate 10-30 focused queries per intent
- Format: [Concept] [Attribute] (e.g., "Diabetes in father", "Chest pain substernal")
- Remove unnecessary words: "history of", "location", "level", "assessment"

Return ONLY valid JSON:
{{
  "is_clinical": true,
  "original_query": "{original_query}",
  "expanded_query": "{expanded_query}",
  "total_intents_detected": number,
  "intents": [
    {{
      "intent_title": "string",
      "description": "string",
      "nature": "string",
      "sub_nature": [
        {{
          "category": "Level2 >> Level3 >> Level4",
          "elements": ["element1", "element2"],
          "entities": ["entity1", "entity2"]
        }}
      ],
      "final_queries": ["query1", "query2", "query3"]
    }}
  ]
}}

User Input: {expanded_query}
Timestamp: {timestamp}
"""


# ==============================================================================
# MAIN PIPELINE CLASS
# ==============================================================================

class ClinicalIntentPipeline:
    """
    Production-ready clinical intent extraction pipeline.
    
    Uses pure LLM reasoning with no hardcoded medical knowledge.
    Generates deep taxonomies and focused queries for CUI extraction.
    """
    
    def __init__(self, project: str, location: str = "us-central1", 
                 model: str = "gemini-2.0-flash-exp"):
        """Initialize pipeline with GCP Vertex AI."""
        aiplatform.init(project=project, location=location)
        self.model = GenerativeModel(model)
    
    
    # --------------------------------------------------------------------------
    # UTILITY METHODS
    # --------------------------------------------------------------------------
    
    def _call_model(self, prompt: str, max_tokens: int = 8192) -> str:
        """Call Vertex AI model with error handling."""
        try:
            if hasattr(self.model, "session") and self.model.session is not None:
                self.model.session.reset()
            
            response = self.model.generate_content(
                prompt,
                generation_config={
                    "temperature": 0.0,
                    "max_output_tokens": max_tokens,
                    "top_p": 0.95,
                    "top_k": 40
                }
            )
            return response.text.strip()
        except Exception as e:
            print(f"Error calling model: {e}")
            return "{}"
    
    def _parse_json(self, text: str) -> Dict[str, Any]:
        """Safely parse JSON from model response."""
        # Remove markdown code blocks
        text = re.sub(r'```json\s*', '', text)
        text = re.sub(r'```\s*', '', text)
        text = text.strip()
        
        try:
            return json.loads(text)
        except:
            # Try to find JSON in text
            match = re.search(r'\{.*\}', text, re.DOTALL)
            if match:
                try:
                    return json.loads(match.group(0))
                except:
                    pass
            return {}
    
    
    # --------------------------------------------------------------------------
    # PIPELINE STEPS
    # --------------------------------------------------------------------------
    
    def expand_query(self, query: str) -> Dict[str, Any]:
        """Step 1: Expand query with medical context."""
        prompt = QUERY_EXPANSION_PROMPT.format(query=query)
        response = self._call_model(prompt)
        data = self._parse_json(response)
        
        return {
            "expanded_query": data.get("expanded_query", query),
            "abbreviations_expanded": data.get("abbreviations_expanded", []),
            "concepts_added": data.get("concepts_added", [])
        }
    
    def extract_intents(self, original_query: str, expanded_query: str) -> Dict[str, Any]:
        """Step 2: Extract intents with inline clinical validation."""
        prompt = INTENT_EXTRACTION_PROMPT.format(
            original_query=original_query,
            expanded_query=expanded_query,
            timestamp=datetime.utcnow().isoformat()
        )
        response = self._call_model(prompt)
        data = self._parse_json(response)
        
        # Check if non-clinical
        if not data.get("is_clinical", True):
            return {
                "is_clinical": False,
                "rejected_reason": data.get("reason", "Not clinical"),
                "intents": []
            }
        
        # Validate intents have final_queries
        intents = []
        for intent in data.get("intents", []):
            if intent.get("final_queries"):
                intents.append(intent)
        
        return {
            "is_clinical": True,
            "intents": intents,
            "total_intents_detected": len(intents)
        }
    
    
    # --------------------------------------------------------------------------
    # MAIN EXECUTION
    # --------------------------------------------------------------------------
    
    def run(self, query: str, verbose: bool = False) -> Dict[str, Any]:
        """
        Execute the complete pipeline.
        
        Args:
            query: User input query
            verbose: Print minimal progress info
            
        Returns:
            Complete results with intents and queries
        """
        start_time = datetime.utcnow()
        
        if verbose:
            print(f"Original Query: {query}")
        
        # Step 1: Expand query
        expansion = self.expand_query(query)
        expanded_query = expansion["expanded_query"]
        
        if verbose:
            print(f"Expanded Query: {expanded_query}")
        
        # Step 2: Extract intents
        extraction = self.extract_intents(query, expanded_query)
        
        # Handle non-clinical queries
        if not extraction.get("is_clinical", True):
            processing_time = (datetime.utcnow() - start_time).total_seconds()
            
            if verbose:
                print(f"Status: NON-CLINICAL (rejected)")
                print(f"Processing Time: {processing_time:.2f}s\n")
            
            return {
                "original_query": query,
                "expanded_query": expanded_query,
                "is_clinical": False,
                "rejected_reason": extraction.get("rejected_reason"),
                "intents": [],
                "statistics": {},
                "processing_time_seconds": processing_time,
                "timestamp": datetime.utcnow().isoformat()
            }
        
        # Calculate statistics
        intents = extraction.get("intents", [])
        total_queries = sum(len(intent.get("final_queries", [])) for intent in intents)
        total_sub_natures = sum(len(intent.get("sub_nature", [])) for intent in intents)
        processing_time = (datetime.utcnow() - start_time).total_seconds()
        
        if verbose:
            print(f"Status: CLINICAL")
            print(f"Intents: {len(intents)} | Sub-natures: {total_sub_natures} | Queries: {total_queries}")
            print(f"Processing Time: {processing_time:.2f}s\n")
        
        return {
            "original_query": query,
            "expanded_query": expanded_query,
            "abbreviations_expanded": expansion.get("abbreviations_expanded", []),
            "concepts_added": expansion.get("concepts_added", []),
            "is_clinical": True,
            "intents": intents,
            "statistics": {
                "total_intents": len(intents),
                "total_sub_natures": total_sub_natures,
                "total_queries": total_queries,
                "avg_queries_per_intent": round(total_queries / len(intents), 2) if intents else 0
            },
            "processing_time_seconds": processing_time,
            "timestamp": datetime.utcnow().isoformat()
        }


# ==============================================================================
# EXAMPLE USAGE
# ==============================================================================

def main():
    """Example usage of the pipeline."""
    
    # Initialize pipeline
    pipeline = ClinicalIntentPipeline(
        project=PROJECT_ID,
        location=LOCATION,
        model=MODEL_NAME
    )
    
    # Test queries
    test_queries = [
        "Family history of diabetes and heart disease",
        "Patient with chest pain radiating to left arm",
        "What is the weather like today?",  # Non-clinical
    ]
    
    # Process queries
    for idx, query in enumerate(test_queries, 1):
        print(f"\n{'='*80}")
        print(f"Query {idx}/{len(test_queries)}")
        print(f"{'='*80}")
        
        result = pipeline.run(query, verbose=True)
        
        # Save to file
        filename = f"query_result_{idx}.json"
        with open(filename, 'w') as f:
            json.dump(result, f, indent=2)
        
        print(f"Saved to: {filename}")


if __name__ == "__main__":
    main()
