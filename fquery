import json
import re
from datetime import datetime
from typing import Dict, Any, List
from google.cloud import aiplatform
from vertexai.generative_models import GenerativeModel

# ======================================================
# PROMPT FOR QUERY EXPANSION
# ======================================================
QUERY_EXPANSION_PROMPT = """
You are an expert clinical AI assistant.

TASK: Expand the user's query into a comprehensive, detailed clinical description.

INSTRUCTIONS:
1. Expand all medical abbreviations.
2. Clarify vague terms.
3. Add relevant clinical context.
4. Identify implicit clinical concepts.
5. Do NOT hallucinate beyond reasonable interpretation.
6. Maintain original query intent.

Return ONLY valid JSON:
{{
  "expanded_query": "comprehensive expanded clinical description",
  "abbreviations_expanded": ["list of abbreviations expanded"],
  "concepts_added": ["list of concepts added"]
}}

User Input: {query}
"""

# ======================================================
# PROMPT FOR INTENT EXTRACTION + FINAL QUERY GENERATION
# ======================================================
INTENT_EXTRACTION_FULL_QUERY_PROMPT = """
You are an expert clinical intent extraction and query engine.

TASKS:

1. Verify if the query is CLINICAL.
   - If NOT, return:
{{
  "is_clinical": false,
  "reason": "Query is not clinical",
  "intents": []
}}

2. If clinical, perform a FULL DYNAMIC DRILL-DOWN of all detected intents:
   - For each intent:
     - Identify intent_title and description
     - Determine nature and sub_nature
     - Dynamically identify sub-components (categories and elements) relevant to that intent
       - Example categories for any intent (illustrative, do NOT hardcode):
         Medication name (Generic Name, Brand Name, Standardized codes)
         Dosage info (Strength, Dosage, Form, Quantity)
         Administration instructions (Prescribing provider, Order type, Order number, Date/time)
         Status and dates (Start date, End date, Medication status)
         Dispensing info (Lot number, Manufacturer, Expiry date)
         Patient info (Patient name, Patient ID, Allergies, Diagnoses)
         Documentation details (Date/time of administration, Admin initials, Confirmation)
   - The model should dynamically create similar sub-components for ANY clinical intent.

3. Generate FINAL QUERIES:
   - Every element in each sub_nature must appear in at least one query.
   - Queries must be clinically meaningful and concise (2–5 words).
   - Combine related elements when appropriate.
   - Cover all dimensions: anatomical, temporal, severity, triggers, associated symptoms.
   - Remove duplicates.
   - Ensure traceability to taxonomy elements.

Return JSON ONLY in the following structure:
{{
  "is_clinical": true,
  "reason": "",
  "original_query": "{original_query}",
  "expanded_query": "{expanded_query}",
  "total_intents_detected": number,
  "intents": [
    {{
      "intent_title": "string",
      "description": "string",
      "nature": "string",
      "sub_nature": [
        {{
          "category": "string",
          "elements": ["concept1", "concept2", "..."],
          "entities": ["entity_type1", "entity_type2", "..."]
        }}
      ],
      "final_queries": [
        "concise query 1",
        "concise query 2",
        "..."
      ]
    }}
  ]
}}

User Input: {expanded_query}
Timestamp: {timestamp}
"""

# ======================================================
# CONTEXTUAL INTENT PIPELINE
# ======================================================
class ContextualIntentPipeline:
    """
    Clinical intent extraction pipeline with fully dynamic LLM reasoning.
    Final queries generated inline, covering all elements.
    """

    def __init__(self, project: str, location: str = "us-central1", 
                 model: str = "gemini-2.0-flash-exp"):
        """
        Initialize pipeline with GCP Vertex AI.

        Args:
            project: GCP project ID
            location: GCP region
            model: Vertex AI model name
        """
        aiplatform.init(project=project, location=location)
        self.model = GenerativeModel(model)

    def _call_model(self, prompt: str, temperature: float = 0.0, max_tokens: int = 8192) -> str:
        try:
            if hasattr(self.model, "session") and self.model.session is not None:
                self.model.session.reset()
            response = self.model.generate_content(
                prompt,
                generation_config={
                    "temperature": temperature,
                    "max_output_tokens": max_tokens,
                    "top_p": 0.95,
                    "top_k": 40
                }
            )
            return response.text.strip()
        except Exception as e:
            print(f"Error calling model: {str(e)}")
            return "{}"

    def _safe_json(self, text: str) -> Dict[str, Any]:
        text = re.sub(r'```json\s*', '', text)
        text = re.sub(r'```\s*', '', text).strip()
        try:
            return json.loads(text)
        except json.JSONDecodeError:
            match = re.search(r'\{.*\}', text, re.DOTALL)
            if match:
                try: return json.loads(match.group(0))
                except: pass
            match = re.search(r'\[.*\]', text, re.DOTALL)
            if match:
                try: return json.loads(match.group(0))
                except: pass
            print(f"Failed to parse JSON from response: {text[:200]}")
            return {}

    def _validate_json_structure(self, data: Dict, required_keys: List[str]) -> bool:
        return all(key in data for key in required_keys)

    # ======================================================
    # STEP 1: QUERY EXPANSION
    # ======================================================
    def expand_query(self, query: str) -> Dict[str, Any]:
        prompt = QUERY_EXPANSION_PROMPT.format(query=query)
        raw_response = self._call_model(prompt)
        data = self._safe_json(raw_response)
        if not self._validate_json_structure(data, ["expanded_query"]):
            return {"expanded_query": query, "abbreviations_expanded": [], "concepts_added": []}
        return {
            "expanded_query": data.get("expanded_query", query),
            "abbreviations_expanded": data.get("abbreviations_expanded", []),
            "concepts_added": data.get("concepts_added", [])
        }

    # ======================================================
    # STEP 2: INTENT EXTRACTION + FINAL QUERY GENERATION
    # ======================================================
    def extract_intents(self, original_query: str, expanded_query: str) -> Dict[str, Any]:
        prompt = INTENT_EXTRACTION_FULL_QUERY_PROMPT.format(
            original_query=original_query,
            expanded_query=expanded_query,
            timestamp=datetime.utcnow().isoformat()
        )
        raw_response = self._call_model(prompt, max_tokens=8192)
        data = self._safe_json(raw_response)

        if not data.get("is_clinical", True):
            return {
                "intents": [],
                "total_intents_detected": 0,
                "is_clinical": False,
                "rejected_reason": data.get("reason", "Query is not clinical"),
                "original_query": original_query,
                "expanded_query": expanded_query
            }

        intents = data.get("intents", [])
        validated_intents = []
        for idx, intent in enumerate(intents):
            if "final_queries" not in intent or not intent["final_queries"]:
                print(f"⚠️ Warning: Intent {idx + 1} '{intent.get('intent_title', 'Unknown')}' has no final_queries. Skipping.")
                continue
            validated_intents.append(intent)

        return {
            "intents": validated_intents,
            "total_intents_detected": data.get("total_intents_detected", len(validated_intents)),
            "is_clinical": True,
            "original_query": data.get("original_query", original_query),
            "expanded_query": data.get("expanded_query", expanded_query)
        }

    # ======================================================
    # FULL PIPELINE
    # ======================================================
    def run(self, query: str, verbose: bool = False) -> Dict[str, Any]:
        start_time = datetime.utcnow()
        if verbose: print(f"Original Query: {query}")

        # Step 1: Expansion
        expansion_result = self.expand_query(query)
        expanded_query = expansion_result["expanded_query"]
        if verbose: print(f"Expanded Query: {expanded_query}")

        # Step 2: Intent extraction + final queries
        intent_result = self.extract_intents(query, expanded_query)
        if not intent_result.get("is_clinical", True):
            processing_time = (datetime.utcnow() - start_time).total_seconds()
            if verbose: print(f"Status: NON-CLINICAL | Processing Time: {processing_time:.2f}s")
            return {
                "original_query": query,
                "expanded_query": expanded_query,
                "intents": [],
                "is_clinical": False,
                "rejected_reason": intent_result.get("rejected_reason"),
                "timestamp": datetime.utcnow().isoformat(),
                "processing_time_seconds": processing_time
            }

        intents = intent_result.get("intents", [])
        total_queries = sum(len(intent.get('final_queries', [])) for intent in intents)
        total_sub_natures = sum(len(intent.get('sub_nature', [])) for intent in intents)
        processing_time = (datetime.utcnow() - start_time).total_seconds()

        if verbose:
            print(f"Status: CLINICAL | Intents: {len(intents)} | Sub-natures: {total_sub_natures} | Queries: {total_queries}")
            print(f"Processing Time: {processing_time:.2f}s")

        return {
            "original_query": query,
            "expanded_query": expanded_query,
            "abbreviations_expanded": expansion_result.get("abbreviations_expanded", []),
            "concepts_added": expansion_result.get("concepts_added", []),
            "intents": intents,
            "is_clinical": True,
            "statistics": {
                "total_intents": len(intents),
                "total_sub_natures": total_sub_natures,
                "total_queries": total_queries,
                "avg_queries_per_intent": round(total_queries / len(intents), 2) if intents else 0
            },
            "processing_time_seconds": processing_time,
            "timestamp": datetime.utcnow().isoformat()
        }

# ======================================================
# EXAMPLE USAGE
# ======================================================
if __name__ == "__main__":
    PROJECT_ID = "your-gcp-project-id"  # Replace with your GCP project ID
    pipeline = ContextualIntentPipeline(project=PROJECT_ID)

    test_queries = [
        "Patient taking multiple medications for hypertension and diabetes",
        "History of chest pain with shortness of breath",
        "Allergies to penicillin and sulfa drugs"
    ]

    for idx, query in enumerate(test_queries, 1):
        print(f"\n{'='*80}\nQuery {idx}/{len(test_queries)}\n{'='*80}")
        result = pipeline.run(query, verbose=True)
        output_filename = f"query_result_{idx}.json"
        with open(output_filename, 'w') as f:
            json.dump(result, f, indent=2)
        print(f"Saved to: {output_filename}")
