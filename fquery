import json
import re
from datetime import datetime
from typing import Dict, Any, List
from google.cloud import aiplatform
from vertexai.generative_models import GenerativeModel

# ======================================================
# PROMPTS
# ======================================================

QUERY_EXPANSION_PROMPT = """
You are an expert medical AI assistant specializing in clinical query expansion.

TASK: Expand the user's query into a detailed clinical description.

INSTRUCTIONS:
1. Expand ALL medical abbreviations (e.g., HTN → Hypertension)
2. Clarify vague medical terms
3. Add relevant context
4. Identify implicit clinical concepts
5. Do NOT hallucinate or add assumptions

Return ONLY valid JSON:
{{
  "expanded_query": "comprehensive expanded clinical description",
  "abbreviations_expanded": ["list of abbreviations expanded"],
  "concepts_added": ["list of concepts made explicit"]
}}

User Input: {query}
"""

INTENT_EXTRACTION_REFINED_PROMPT = """
You are an expert clinical intent extraction engine.

TASKS:

1. Determine if the query is CLINICAL.
   - If NOT clinical, return:
{{
  "is_clinical": false,
  "reason": "Query is not clinical",
  "intents": []
}}

2. If clinical, extract all relevant intents and their hierarchy:
   - Each intent must include: intent_title, description, nature, sub_nature
   - Each sub_nature must include: category, elements, entities

3. For each intent, generate FINAL QUERIES that satisfy:
   - Based explicitly on nature, sub_nature, category, and elements
   - Concise: 2–5 words
   - Remove duplicates
   - Each query should cover multiple dimensions: anatomical, temporal, severity, functional, triggers, associated symptoms
   - Target 2–15 CUIs per query
   - Ensure traceability to taxonomy elements

4. Return structured JSON exactly in this format:
{{
  "is_clinical": true,
  "reason": "",
  "original_query": "{original_query}",
  "expanded_query": "{expanded_query}",
  "total_intents_detected": number,
  "intents": [
    {{
      "intent_title": "string",
      "description": "string",
      "nature": "string",
      "sub_nature": [
        {{
          "category": "string",
          "elements": ["concept1", "concept2"],
          "entities": ["entity_type1", "entity_type2"]
        }}
      ],
      "final_queries": [
        "concise query 1",
        "concise query 2"
      ]
    }}
  ]
}}

User Input: {expanded_query}
Timestamp: {timestamp}
"""

# ======================================================
# PIPELINE
# ======================================================

class RefinedIntentPipeline:
    """
    Clinical intent extraction pipeline with built-in query refinement.
    """

    def __init__(self, project: str, location: str = "us-central1",
                 model: str = "gemini-2.0-flash-exp"):
        aiplatform.init(project=project, location=location)
        self.model = GenerativeModel(model)

    def _call_model(self, prompt: str, temperature: float = 0.0, max_tokens: int = 8192) -> str:
        try:
            if hasattr(self.model, "session") and self.model.session is not None:
                self.model.session.reset()
            response = self.model.generate_content(
                prompt,
                generation_config={
                    "temperature": temperature,
                    "max_output_tokens": max_tokens,
                    "top_p": 0.95,
                    "top_k": 40
                }
            )
            return response.text.strip()
        except Exception as e:
            print(f"Error calling model: {str(e)}")
            return "{}"

    def _safe_json(self, text: str) -> Dict[str, Any]:
        text = re.sub(r'```json\s*', '', text)
        text = re.sub(r'```\s*', '', text).strip()
        try:
            return json.loads(text)
        except json.JSONDecodeError:
            match = re.search(r'\{.*\}', text, re.DOTALL)
            if match:
                try:
                    return json.loads(match.group(0))
                except:
                    pass
            return {}

    # -------------------------------
    # STEP 1: Query Expansion
    # -------------------------------
    def expand_query(self, query: str) -> Dict[str, Any]:
        prompt = QUERY_EXPANSION_PROMPT.format(query=query)
        raw_response = self._call_model(prompt)
        data = self._safe_json(raw_response)
        if "expanded_query" not in data:
            return {"expanded_query": query, "abbreviations_expanded": [], "concepts_added": []}
        return {
            "expanded_query": data.get("expanded_query", query),
            "abbreviations_expanded": data.get("abbreviations_expanded", []),
            "concepts_added": data.get("concepts_added", [])
        }

    # -------------------------------
    # STEP 2: Intent Extraction + Refined Query Generation
    # -------------------------------
    def extract_intents_refined(self, original_query: str, expanded_query: str) -> Dict[str, Any]:
        prompt = INTENT_EXTRACTION_REFINED_PROMPT.format(
            original_query=original_query,
            expanded_query=expanded_query,
            timestamp=datetime.utcnow().isoformat()
        )
        raw_response = self._call_model(prompt, max_tokens=8192)
        data = self._safe_json(raw_response)

        if not data.get("is_clinical", True):
            return {
                "intents": [],
                "total_intents_detected": 0,
                "is_clinical": False,
                "rejected_reason": data.get("reason", "Query not clinical"),
                "original_query": original_query,
                "expanded_query": expanded_query
            }
        return data

    # -------------------------------
    # RUN FULL PIPELINE
    # -------------------------------
    def run(self, query: str, verbose: bool = False) -> Dict[str, Any]:
        start_time = datetime.utcnow()
        if verbose:
            print(f"Original Query: {query}")

        expansion_result = self.expand_query(query)
        expanded_query = expansion_result["expanded_query"]
        if verbose:
            print(f"Expanded Query: {expanded_query}")

        intent_result = self.extract_intents_refined(query, expanded_query)
        processing_time = (datetime.utcnow() - start_time).total_seconds()

        if not intent_result.get("is_clinical", True):
            if verbose:
                print(f"Status: NON-CLINICAL | Time: {processing_time:.2f}s\n")
            return {
                "original_query": query,
                "expanded_query": expanded_query,
                "intents": [],
                "is_clinical": False,
                "rejected_reason": intent_result.get("rejected_reason"),
                "timestamp": datetime.utcnow().isoformat(),
                "processing_time_seconds": processing_time
            }

        intents = intent_result.get("intents", [])
        total_queries = sum(len(intent.get('final_queries', [])) for intent in intents)
        total_sub_natures = sum(len(intent.get('sub_nature', [])) for intent in intents)

        if verbose:
            print(f"Status: CLINICAL | Intents: {len(intents)} | Sub-natures: {total_sub_natures} | Queries: {total_queries}")
            print(f"Processing Time: {processing_time:.2f}s\n")

        return {
            "original_query": query,
            "expanded_query": expanded_query,
            "abbreviations_expanded": expansion_result.get("abbreviations_expanded", []),
            "concepts_added": expansion_result.get("concepts_added", []),
            "intents": intents,
            "is_clinical": True,
            "statistics": {
                "total_intents": len(intents),
                "total_sub_natures": total_sub_natures,
                "total_queries": total_queries,
                "avg_queries_per_intent": round(total_queries / len(intents), 2) if intents else 0
            },
            "processing_time_seconds": processing_time,
            "timestamp": datetime.utcnow().isoformat()
        }

# ======================================================
# USAGE EXAMPLE
# ======================================================

if __name__ == "__main__":
    PROJECT_ID = "your-gcp-project-id"

    pipeline = RefinedIntentPipeline(
        project=PROJECT_ID,
        location="us-central1",
        model="gemini-2.0-flash-exp"
    )

    test_queries = [
        "Family history of diabetes",
        "Patient with chest pain and shortness of breath",
        "What is the weather like today?"
    ]

    for idx, query in enumerate(test_queries, 1):
        print(f"\n{'='*80}\nQuery {idx}/{len(test_queries)}\n{'='*80}")
        result = pipeline.run(query, verbose=True)
        output_filename = f"query_result_refined_{idx}.json"
        with open(output_filename, 'w') as f:
            json.dump(result, f, indent=2)
        print(f"Saved to: {output_filename}")
