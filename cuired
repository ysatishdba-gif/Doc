"""
PRODUCTION CUI REDUCTION SYSTEM - FINAL CLEAN VERSION
======================================================
✓ Fixed: Always returns results
✓ Clean logging - only essential messages
✓ Optional detailed stats
"""

import time
import threading
import logging
import traceback
from typing import List, Dict, Optional, Set, Tuple, Any
from dataclasses import dataclass, field
from collections import defaultdict
from enum import Enum
import numpy as np
import networkx as nx
import pickle
import psutil
import requests
import subprocess
from functools import wraps
from concurrent.futures import ThreadPoolExecutor, as_completed
from google.cloud import bigquery
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ========================= LOGGING =========================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

print_lock = threading.Lock()

def log(msg: str, level: str = "INFO"):
    """Thread-safe logging"""
    with print_lock:
        if level == "ERROR":
            logger.error(msg)
        elif level == "WARNING":
            logger.warning(msg)
        else:
            logger.info(msg)

# ========================= PERFORMANCE MONITORING =========================

class PerformanceMonitor:
    """Track performance metrics"""
    def __init__(self):
        self.metrics = defaultdict(list)
        self.lock = threading.Lock()
    
    def record(self, metric_name: str, value: float):
        with self.lock:
            self.metrics[metric_name].append(value)
    
    def get_summary(self) -> Dict[str, Dict[str, float]]:
        with self.lock:
            summary = {}
            for name, values in self.metrics.items():
                if values:
                    summary[name] = {
                        'count': len(values),
                        'mean': np.mean(values),
                        'p95': np.percentile(values, 95),
                        'min': np.min(values),
                        'max': np.max(values)
                    }
            return summary

perf_monitor = PerformanceMonitor()

def monitor_perf(metric_name: str):
    """Decorator to monitor function performance"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            start = time.time()
            try:
                result = func(*args, **kwargs)
                elapsed = (time.time() - start) * 1000
                perf_monitor.record(metric_name, elapsed)
                return result
            except Exception:
                elapsed = (time.time() - start) * 1000
                perf_monitor.record(f"{metric_name}_error", elapsed)
                raise
        return wrapper
    return decorator

# ========================= ADAPTIVE CACHING =========================

class AdaptiveLRUCache:
    """Memory-aware LRU cache"""
    def __init__(self, memory_threshold: float = 0.2):
        self.cache = {}
        self.order = []
        self.lock = threading.RLock()
        self.memory_threshold = memory_threshold
        self.hits = 0
        self.misses = 0
    
    def get(self, key):
        with self.lock:
            if key in self.cache:
                self.order.remove(key)
                self.order.append(key)
                self.hits += 1
                return self.cache[key]
            self.misses += 1
            return None
    
    def put(self, key, value):
        with self.lock:
            if key in self.cache:
                self.order.remove(key)
            self.cache[key] = value
            self.order.append(key)
            self._evict_if_needed()
    
    def _evict_if_needed(self):
        try:
            mem = psutil.virtual_memory()
            while mem.available < self.memory_threshold * mem.total and self.order:
                oldest = self.order.pop(0)
                del self.cache[oldest]
                mem = psutil.virtual_memory()
        except Exception:
            pass
    
    def get_stats(self) -> Dict:
        with self.lock:
            total = self.hits + self.misses
            return {
                'size': len(self.cache),
                'hit_rate': self.hits / total if total > 0 else 0.0
            }

# ========================= ENUMS =========================

class ScoringMode(Enum):
    ASSESSMENT = "assessment"
    REDUCTION = "reduction"

class UsageContext(Enum):
    QUERY = "query"
    DOCUMENT = "document"

# ========================= DATA MODELS =========================

@dataclass
class CUIMetadata:
    cui: str
    preferred_term: str
    semantic_types: List[str]
    tokens: List[str]
    token_count: int
    ic_score: float
    
    @staticmethod
    def tokenize(text: str) -> List[str]:
        import re
        text = re.sub(r'[^\w\s-]', ' ', text.lower())
        tokens = [t.strip() for t in text.split() if t.strip() and len(t) > 1]
        return tokens

@dataclass
class ComponentScore:
    name: str
    score: float
    weight: float
    explanation: str
    details: Dict = field(default_factory=dict)
    
    @property
    def weighted_score(self) -> float:
        return self.score * self.weight

@dataclass
class CUIScore:
    cui: str
    preferred_term: str
    completeness_score: float
    component_scores: List[ComponentScore]
    retained_cuis: List[str]
    ranking: Optional[int] = None

@dataclass
class ReductionResult:
    mode: ScoringMode
    usage_context: UsageContext
    input_cuis: List[str]
    output_cuis: List[str]
    scores: Dict[str, CUIScore]
    retention_map: Dict[str, List[str]]
    processing_time_ms: float
    metadata: Dict = field(default_factory=dict)

# ========================= HIERARCHY CLIENT =========================

class HierarchyClient:
    """NetworkX-based UMLS hierarchy with caching"""
    
    def __init__(self, network_obj: nx.DiGraph, ic_scores: Optional[Dict[str, float]] = None):
        self.network = network_obj
        self.ic_scores = ic_scores or {}
        self.ancestors_cache = AdaptiveLRUCache()
        self.children_cache = AdaptiveLRUCache()
        self.ic_cache = AdaptiveLRUCache()
        self.hierarchy_cache = AdaptiveLRUCache()
    
    def get_children(self, cui: str) -> List[str]:
        cached = self.children_cache.get(cui)
        if cached is not None:
            return cached
        children = list(self.network.successors(cui)) if self.network.has_node(cui) else []
        self.children_cache.put(cui, children)
        return children
    
    def get_parents(self, cui: str) -> List[str]:
        return list(self.network.predecessors(cui)) if self.network.has_node(cui) else []
    
    def get_ancestors(self, cui: str, max_depth: int = 10) -> List[List[str]]:
        key = (cui, max_depth)
        cached = self.ancestors_cache.get(key)
        if cached is not None:
            return cached
        
        queue = [(0, [cui])]
        visited = set()
        paths = []
        
        while queue:
            depth, path = queue.pop(0)
            node = path[-1]
            if node in visited:
                continue
            visited.add(node)
            
            if depth >= max_depth or not self.network.has_node(node):
                paths.append(path)
                continue
            
            parents = self.get_parents(node)
            if not parents:
                paths.append(path)
            else:
                for parent in parents:
                    queue.append((depth + 1, path + [parent]))
        
        self.ancestors_cache.put(key, paths)
        return paths
    
    def get_ic_score(self, cui: str) -> float:
        cached = self.ic_cache.get(cui)
        if cached is not None:
            return cached
        
        if cui in self.ic_scores:
            ic = self.ic_scores[cui]
        else:
            paths = self.get_ancestors(cui)
            if paths:
                avg_depth = sum(len(p) for p in paths) / len(paths)
                ic = min(10.0, 2.0 + np.log1p(avg_depth) * 2.0)
            else:
                ic = 3.0
        
        self.ic_cache.put(cui, ic)
        return ic
    
    def is_hierarchical_descendant(self, cui_child: str, cui_parent: str) -> bool:
        key = (cui_child, cui_parent)
        cached = self.hierarchy_cache.get(key)
        if cached is not None:
            return cached
        
        try:
            if self.network.has_node(cui_child) and self.network.has_node(cui_parent):
                has_path = nx.has_path(self.network, cui_child, cui_parent)
            else:
                has_path = False
        except Exception:
            has_path = False
        
        self.hierarchy_cache.put(key, has_path)
        return has_path

# ========================= AUTO CONFIGURATION =========================

class AutoConfiguration:
    """Auto-compute configuration from UMLS"""
    
    def __init__(self, bq_client: bigquery.Client, project_id: str, dataset_id: str):
        self.bq = bq_client
        self.project_id = project_id
        self.dataset_id = dataset_id
        self._config_cache = None
        self._lock = threading.Lock()
    
    def get_config(self, sample_size: int = 5000) -> Dict:
        with self._lock:
            if self._config_cache is not None:
                return self._config_cache
            
            log("Computing configuration from UMLS...")
            start = time.time()
            
            config = {
                'weights': self._compute_weights(sample_size),
                'params': self._compute_params(sample_size),
                'modifiers': self._discover_modifiers()
            }
            
            log(f"Configuration ready ({time.time() - start:.1f}s)")
            self._config_cache = config
            return config
    
    def _compute_weights(self, sample_size: int) -> Dict[str, float]:
        query = f"""
        WITH sample AS (
          SELECT DISTINCT CUI FROM `{self.project_id}.{self.dataset_id}.MRCONSO`
          WHERE LAT = 'ENG' AND ISPREF = 'Y' LIMIT {sample_size}
        ),
        cui_term_counts AS (
          SELECT c.CUI, c.STR, COUNT(*) as term_frequency
          FROM `{self.project_id}.{self.dataset_id}.MRCONSO` c
          JOIN sample s ON c.CUI = s.CUI
          WHERE c.LAT = 'ENG' AND c.ISPREF = 'Y'
          GROUP BY c.CUI, c.STR
        ),
        features AS (
          SELECT 
            ctc.CUI,
            ARRAY_LENGTH(SPLIT(ctc.STR, ' ')) as tokens,
            (SELECT COUNT(*) FROM `{self.project_id}.{self.dataset_id}.MRREL` r 
             WHERE r.CUI1 = ctc.CUI AND r.REL IN ('PAR','CHD')) as rels,
            (SELECT COUNT(DISTINCT TUI) FROM `{self.project_id}.{self.dataset_id}.MRSTY` s 
             WHERE s.CUI = ctc.CUI) as types,
            -LOG(SAFE_DIVIDE(ctc.term_frequency, {sample_size})) as ic
          FROM cui_term_counts ctc
        )
        SELECT CORR(tokens, ic) as token_corr, CORR(rels, ic) as rel_corr, CORR(types, ic) as type_corr
        FROM features
        WHERE tokens IS NOT NULL AND rels IS NOT NULL AND types IS NOT NULL AND ic IS NOT NULL
        """
        
        try:
            row = next(self.bq.query(query, timeout=300).result())
            corrs = {
                'token': max(0.1, abs(row.token_corr or 0.3)),
                'hierarchy': max(0.1, abs(row.rel_corr or 0.3)),
                'diversity': max(0.1, abs(row.type_corr or 0.2))
            }
            total = sum(corrs.values())
            base = 0.85
            
            weights = {
                'token_subsumption': (corrs['token'] / total) * base * 0.4,
                'umls_hierarchy': (corrs['hierarchy'] / total) * base * 0.4,
                'term_specificity': (corrs['token'] / total) * base * 0.3,
                'modifier_presence': (corrs['diversity'] / total) * base * 0.3,
                'semantic_similarity': 0.15
            }
            
            total_weight = sum(weights.values())
            return {k: v / total_weight for k, v in weights.items()}
        except Exception as e:
            log(f"Weight computation failed, using defaults: {e}", "WARNING")
            return {'token_subsumption': 0.20, 'umls_hierarchy': 0.20, 'term_specificity': 0.20,
                    'modifier_presence': 0.20, 'semantic_similarity': 0.20}
    
    def _compute_params(self, sample_size: int) -> Dict[str, float]:
        query = f"""
        WITH sample AS (
          SELECT DISTINCT CUI FROM `{self.project_id}.{self.dataset_id}.MRCONSO`
          WHERE LAT = 'ENG' AND ISPREF = 'Y' LIMIT {sample_size}
        ),
        cui_term_counts AS (
          SELECT c.CUI, c.STR, COUNT(*) as term_frequency
          FROM `{self.project_id}.{self.dataset_id}.MRCONSO` c
          JOIN sample s ON c.CUI = s.CUI
          WHERE c.LAT = 'ENG' AND c.ISPREF = 'Y'
          GROUP BY c.CUI, c.STR
        ),
        ic_computed AS (
          SELECT CUI, -LOG(SAFE_DIVIDE(term_frequency, {sample_size})) as ic
          FROM cui_term_counts
        ),
        ic_dist AS (
          SELECT APPROX_QUANTILES(ic, 100) as ic_percentiles
          FROM ic_computed WHERE ic IS NOT NULL
        ),
        rel_counts AS (
          SELECT r.CUI1, COUNT(DISTINCT r.CUI2) as related_count
          FROM `{self.project_id}.{self.dataset_id}.MRREL` r
          JOIN sample s ON r.CUI1 = s.CUI
          WHERE r.REL IN ('PAR','CHD','RB','RN')
          GROUP BY r.CUI1
        ),
        rel_dist AS (
          SELECT APPROX_QUANTILES(related_count, 100) as rel_percentiles, AVG(related_count) as mean_rels
          FROM rel_counts
        ),
        parent_counts AS (
          SELECT s.CUI, COUNT(DISTINCT r.CUI2) as parent_count
          FROM sample s
          LEFT JOIN `{self.project_id}.{self.dataset_id}.MRREL` r ON s.CUI = r.CUI1 AND r.REL = 'PAR'
          GROUP BY s.CUI
        ),
        depth_stats AS (
          SELECT AVG(parent_count) as mean_depth FROM parent_counts
        )
        SELECT ic.ic_percentiles, rel.rel_percentiles, rel.mean_rels, depth.mean_depth
        FROM ic_dist ic, rel_dist rel, depth_stats depth
        """
        
        try:
            row = next(self.bq.query(query, timeout=300).result())
            ic_p = row.ic_percentiles
            rel_p = row.rel_percentiles
            
            return {
                'ic_min_threshold': float(ic_p[25]),
                'prefilter_target_size': float(rel_p[75] * 15),
                'max_clusters': float(rel_p[60] * 3),
                'hierarchy_sample_size': float(row.mean_depth * 15),
                'embedding_sample_size': float(row.mean_depth * 7.5),
                'final_cui_count_query': float(min(5, max(2, row.mean_rels * 0.15))),
                'final_cui_count_document': float(min(8, max(3, row.mean_rels * 0.25))),
                'retention_top_k': float(rel_p[60] * 0.9)
            }
        except Exception as e:
            log(f"Param computation failed, using defaults: {e}", "WARNING")
            return {'ic_min_threshold': 2.0, 'prefilter_target_size': 1000.0, 'max_clusters': 200.0,
                    'hierarchy_sample_size': 100.0, 'embedding_sample_size': 50.0,
                    'final_cui_count_query': 3.0, 'final_cui_count_document': 5.0, 'retention_top_k': 50.0}
    
    def _discover_modifiers(self) -> Dict[str, Set[str]]:
        query = f"""
        WITH type_stats AS (
          SELECT s.TUI, s.STY, COUNT(DISTINCT c.CUI) as cui_count, COUNT(DISTINCT c.STR) as term_count
          FROM `{self.project_id}.{self.dataset_id}.MRSTY` s
          JOIN `{self.project_id}.{self.dataset_id}.MRCONSO` c ON s.CUI = c.CUI
          WHERE c.LAT = 'ENG' AND LENGTH(c.STR) BETWEEN 3 AND 20
          GROUP BY s.TUI, s.STY
        )
        SELECT TUI, STY FROM type_stats
        WHERE cui_count > 10 AND term_count > 20
        ORDER BY cui_count DESC LIMIT 10
        """
        
        modifiers = {}
        try:
            for row in self.bq.query(query, timeout=60).result():
                term_query = f"""
                SELECT DISTINCT LOWER(c.STR) as term
                FROM `{self.project_id}.{self.dataset_id}.MRCONSO` c
                JOIN `{self.project_id}.{self.dataset_id}.MRSTY` s ON c.CUI = s.CUI
                WHERE s.TUI = @tui AND c.LAT = 'ENG' AND LENGTH(c.STR) BETWEEN 3 AND 20
                LIMIT 100
                """
                job_config = bigquery.QueryJobConfig(
                    query_parameters=[bigquery.ScalarQueryParameter("tui", "STRING", row.TUI)]
                )
                terms = {r.term for r in self.bq.query(term_query, job_config=job_config, timeout=60).result()}
                if terms:
                    modifiers[row.STY.lower().replace(' ', '_').replace('-', '_')] = terms
        except Exception as e:
            log(f"Modifier discovery failed: {e}", "WARNING")
        
        return modifiers

# ========================= PIPELINE STAGES =========================

class PreFilter:
    def __init__(self, hierarchy: HierarchyClient):
        self.hierarchy = hierarchy
    
    @monitor_perf("prefilter")
    def filter(self, cuis: List[str], params: Dict) -> Tuple[List[str], Dict]:
        ic_thresh = params.get('ic_min_threshold', 2.0)
        target = int(params.get('prefilter_target_size', 1000))
        
        # IC filter
        cuis = [c for c in cuis if self.hierarchy.get_ic_score(c) >= ic_thresh]
        
        # Remove ancestors
        cui_set = set(cuis)
        to_remove = set()
        for cui in cuis:
            for parent in self.hierarchy.get_parents(cui):
                if parent in cui_set:
                    to_remove.add(parent)
        cuis = [c for c in cuis if c not in to_remove]
        
        # Sample if needed
        if len(cuis) > target:
            import random
            buckets = defaultdict(list)
            for c in cuis:
                buckets[int(self.hierarchy.get_ic_score(c))].append(c)
            
            sampled = []
            for bucket_key in sorted(buckets.keys()):
                bucket = buckets[bucket_key]
                prop = len(bucket) / len(cuis)
                n = max(1, int(target * prop))
                sampled.extend(random.sample(bucket, min(n, len(bucket))))
            
            if len(sampled) > target:
                sampled.sort(key=lambda c: self.hierarchy.get_ic_score(c), reverse=True)
                sampled = sampled[:target]
            cuis = sampled
        
        return cuis, {'output': len(cuis)}

class Clusterer:
    def __init__(self, hierarchy: HierarchyClient):
        self.hierarchy = hierarchy
    
    @monitor_perf("clustering")
    def cluster(self, cuis: List[str], params: Dict) -> Dict[str, List[str]]:
        max_clusters = int(params.get('max_clusters', 200))
        
        groups = defaultdict(list)
        for cui in cuis:
            paths = self.hierarchy.get_ancestors(cui, max_depth=5)
            ancestor = paths[0][min(3, len(paths[0]) - 1)] if paths and len(paths[0]) >= 3 else cui
            groups[ancestor].append(cui)
        
        if len(groups) > max_clusters:
            sorted_groups = sorted(groups.items(), key=lambda x: len(x[1]))
            large = {k: v for k, v in sorted_groups[-(max_clusters - 1):]}
            small = []
            for k, v in sorted_groups[:-(max_clusters - 1)]:
                small.extend(v)
            large['MERGED'] = small
            groups = large
        
        return dict(groups)

class Scorer:
    def __init__(self, config: Dict, hierarchy: HierarchyClient, bq: bigquery.Client, proj: str, ds: str):
        self.config = config
        self.hierarchy = hierarchy
        self.bq = bq
        self.project_id = proj
        self.dataset_id = ds
        self.metadata_cache = AdaptiveLRUCache()
        self.token_index = defaultdict(set)
    
    @monitor_perf("scoring")
    def score(self, cuis: List[str], embeddings: Dict[str, np.ndarray]) -> Dict[str, CUIScore]:
        metadata = self._fetch_metadata(cuis)
        self._build_index(metadata)
        self._embeddings = embeddings
        
        scored = {}
        with ThreadPoolExecutor(max_workers=4) as ex:
            futures = {ex.submit(self._score_cui, c, metadata): c for c in cuis}
            for future in as_completed(futures, timeout=300):
                cui = futures[future]
                try:
                    scored[cui] = future.result()
                except Exception as e:
                    log(f"Scoring error for {cui}: {e}", "ERROR")
        
        return scored
    
    def _build_index(self, metadata: Dict):
        self.token_index.clear()
        for cui, meta in metadata.items():
            for token in meta.tokens:
                self.token_index[token].add(cui)
    
    def _score_cui(self, cui: str, all_meta: Dict) -> CUIScore:
        meta = all_meta[cui]
        components = []
        weights = self.config['weights']
        params = self.config['params']
        
        # Token subsumption
        cui_tokens = set(meta.tokens)
        candidates = set()
        for t in cui_tokens:
            candidates.update(self.token_index.get(t, set()))
        candidates.discard(cui)
        
        subsumed = sum(1 for oc in candidates 
                       if (ot := set(all_meta[oc].tokens)) and ot.issubset(cui_tokens) and len(cui_tokens) > len(ot))
        total = len(all_meta) - 1
        token_score = subsumed / total if total > 0 else 0.0
        
        components.append(ComponentScore("Token", token_score, weights['token_subsumption'], "", {}))
        
        # Hierarchy
        import random
        others = [c for c in all_meta if c != cui]
        sample_size = int(params.get('hierarchy_sample_size', 100))
        sampled = random.sample(others, min(sample_size, len(others))) if others else []
        hier_count = sum(1 for oc in sampled if self.hierarchy.is_hierarchical_descendant(cui, oc))
        hier_score = hier_count / len(sampled) if sampled else 0.0
        
        components.append(ComponentScore("Hierarchy", hier_score, weights['umls_hierarchy'], "", {}))
        
        # Specificity
        ic = meta.ic_score
        tokens = meta.token_count
        spec_score = 0.6 * min(ic / 10, 1.0) + 0.4 * min(tokens / 6, 1.0)
        
        components.append(ComponentScore("Specificity", spec_score, weights['term_specificity'], "", {}))
        
        # Modifiers
        cui_tok_set = set(meta.tokens)
        mod_types = [mt for mt, terms in self.config['modifiers'].items() if cui_tok_set & terms]
        total_types = len(self.config['modifiers'])
        mod_score = len(mod_types) / total_types if total_types > 0 else 0.0
        
        components.append(ComponentScore("Modifiers", mod_score, weights['modifier_presence'], "", {}))
        
        # Semantic similarity
        if hasattr(self, '_embeddings') and cui in self._embeddings:
            cui_emb = self._embeddings[cui]
            other_embs = [c for c in all_meta if c != cui and c in self._embeddings]
            emb_sample_size = int(params.get('embedding_sample_size', 50))
            sampled_embs = random.sample(other_embs, min(emb_sample_size, len(other_embs))) if other_embs else []
            
            if sampled_embs:
                sims = [np.dot(cui_emb, self._embeddings[oc]) / 
                        (np.linalg.norm(cui_emb) * np.linalg.norm(self._embeddings[oc]))
                        for oc in sampled_embs]
                sem_score = float(np.mean(sims))
            else:
                sem_score = 0.5
        else:
            sem_score = 0.5
        
        components.append(ComponentScore("Semantic", sem_score, weights['semantic_similarity'], "", {}))
        
        final = sum(c.weighted_score for c in components)
        return CUIScore(cui, meta.preferred_term, final, components, [])
    
    def _fetch_metadata(self, cuis: List[str]) -> Dict[str, CUIMetadata]:
        cached = {c: self.metadata_cache.get(c) for c in cuis if self.metadata_cache.get(c)}
        missing = [c for c in cuis if c not in cached]
        
        if missing:
            query = f"""
            SELECT c.CUI as cui, c.STR as term, ARRAY_AGG(DISTINCT s.TUI) as types
            FROM `{self.project_id}.{self.dataset_id}.MRCONSO` c
            LEFT JOIN `{self.project_id}.{self.dataset_id}.MRSTY` s ON c.CUI = s.CUI
            WHERE c.CUI IN UNNEST(@cuis) AND c.LAT = 'ENG' AND c.ISPREF = 'Y'
            GROUP BY c.CUI, c.STR
            """
            job_config = bigquery.QueryJobConfig(
                query_parameters=[bigquery.ArrayQueryParameter("cuis", "STRING", missing)]
            )
            
            try:
                for row in self.bq.query(query, job_config=job_config, timeout=300).result():
                    tokens = CUIMetadata.tokenize(row.term)
                    ic = self.hierarchy.get_ic_score(row.cui)
                    meta = CUIMetadata(row.cui, row.term, row.types or [], tokens, len(tokens), ic)
                    self.metadata_cache.put(row.cui, meta)
                    cached[row.cui] = meta
            except Exception as e:
                log(f"Metadata fetch error: {e}", "ERROR")
        
        return cached

# ========================= MAIN SYSTEM =========================

class CUIReductionSystem:
    """Complete CUI reduction pipeline"""
    
    def __init__(self, project_id: str, dataset_id: str, network_path: str, 
                 ic_scores: Optional[Dict[str, float]] = None):
        log("Initializing CUI Reduction System...")
        
        # Load network
        with open(network_path, 'rb') as f:
            network = pickle.load(f)
        log(f"Loaded network: {network.number_of_nodes():,} nodes")
        
        self.bq = bigquery.Client(project=project_id)
        self.hierarchy = HierarchyClient(network, ic_scores)
        self.auto_config = AutoConfiguration(self.bq, project_id, dataset_id)
        self.config = self.auto_config.get_config()
        self.project_id = project_id
        self.dataset_id = dataset_id
        
        self.prefilter = PreFilter(self.hierarchy)
        self.clusterer = Clusterer(self.hierarchy)
        self.scorer = Scorer(self.config, self.hierarchy, self.bq, project_id, dataset_id)
        
        log("System ready\n")
    
    @monitor_perf("full_pipeline")
    def reduce(self, cuis: List[str], embeddings: Dict[str, np.ndarray],
               usage_context: UsageContext = UsageContext.QUERY) -> ReductionResult:
        """Execute CUI reduction pipeline"""
        
        if not cuis:
            log("Warning: Empty CUI list provided", "WARNING")
            return ReductionResult(ScoringMode.REDUCTION, usage_context, [], [], {}, {}, 0, {})
        
        start = time.time()
        log(f"Reducing {len(cuis)} CUIs...")
        
        # Stage 1: Pre-filter
        filtered, _ = self.prefilter.filter(cuis, self.config['params'])
        
        if not filtered:
            log("Warning: All CUIs filtered out in pre-filter stage", "WARNING")
            return ReductionResult(ScoringMode.REDUCTION, usage_context, cuis, [], {}, {}, 
                                   (time.time() - start) * 1000, {})
        
        # Stage 2: Cluster
        clusters = self.clusterer.cluster(filtered, self.config['params'])
        representatives = []
        for cluster_cuis in clusters.values():
            if len(cluster_cuis) == 1:
                representatives.append(cluster_cuis[0])
            else:
                representatives.append(max(cluster_cuis, key=lambda c: self.hierarchy.get_ic_score(c)))
        
        if not representatives:
            log("Warning: No cluster representatives found", "WARNING")
            return ReductionResult(ScoringMode.REDUCTION, usage_context, cuis, [], {}, {},
                                   (time.time() - start) * 1000, {})
        
        # Stage 3: Score
        scored_embeddings = {c: e for c, e in embeddings.items() if c in representatives}
        scored = self.scorer.score(representatives, scored_embeddings)
        
        if not scored:
            log("Warning: No CUIs scored successfully", "WARNING")
            return ReductionResult(ScoringMode.REDUCTION, usage_context, cuis, [], {}, {},
                                   (time.time() - start) * 1000, {})
        
        # Stage 4 & 5: Select final (FIXED LOGIC)
        sorted_cuis = sorted(scored.keys(), key=lambda c: scored[c].completeness_score, reverse=True)
        max_final = int(self.config['params'].get(f'final_cui_count_{usage_context.value}', 3))
        
        # SIMPLE SELECTION: Just take top N by score
        selected = sorted_cuis[:max_final]
        
        # Build retention map (optional, for metadata)
        retention = {}
        
        elapsed = (time.time() - start) * 1000
        log(f"Completed: {len(cuis)} → {len(selected)} CUIs ({elapsed:.0f}ms)\n")
        
        return ReductionResult(
            ScoringMode.REDUCTION, usage_context, cuis, selected, scored, retention, elapsed,
            {'num_clusters': len(clusters), 'num_scored': len(scored)}
        )
    
    def get_stats(self) -> Dict:
        """Get performance stats (optional)"""
        return perf_monitor.get_summary()

# ========================= UTILITIES =========================

class CUIExtractor:
    def __init__(self, api_url: str):
        self.api_url = api_url
        self.session = requests.Session()
        
        try:
            token = subprocess.run(['gcloud', 'auth', 'print-identity-token'],
                                   stdout=subprocess.PIPE, universal_newlines=True, timeout=30).stdout.strip()
            self.headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}
        except Exception:
            self.headers = {"Content-Type": "application/json"}
        
        retry = Retry(total=3, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504])
        self.session.mount("https://", HTTPAdapter(max_retries=retry))
    
    def extract(self, text: str) -> List[str]:
        try:
            resp = self.session.post(self.api_url, headers=self.headers,
                                     json={"query_texts": [text], "top_k": 3}, timeout=200)
            resp.raise_for_status()
            cuis = []
            for v in resp.json().values():
                if isinstance(v, list):
                    cuis.extend(v)
            return list(set(map(str, cuis)))
        except Exception as e:
            log(f"Extraction failed: {e}", "ERROR")
            return []

def filter_by_sab(cuis: List[str], proj: str, ds: str, sabs: List[str]) -> List[str]:
    if not cuis:
        return []
    
    client = bigquery.Client(project=proj)
    filtered = []
    
    for i in range(0, len(cuis), 2000):
        batch = cuis[i:i+2000]
        query = f"SELECT DISTINCT CUI FROM `{proj}.{ds}.MRCONSO` WHERE CUI IN UNNEST(@c) AND SAB IN UNNEST(@s)"
        job_config = bigquery.QueryJobConfig(query_parameters=[
            bigquery.ArrayQueryParameter("c", "STRING", batch),
            bigquery.ArrayQueryParameter("s", "STRING", sabs)
        ])
        try:
            filtered.extend([r.CUI for r in client.query(query, job_config=job_config, timeout=200).result()])
        except Exception as e:
            log(f"SAB filter error: {e}", "ERROR")
    
    return filtered

def fetch_embeddings(cuis: List[str], proj: str, ds: str, table: str) -> Dict[str, np.ndarray]:
    client = bigquery.Client(project=proj)
    embs = {}
    
    for i in range(0, len(cuis), 2000):
        batch = cuis[i:i+2000]
        query = f"SELECT CUI, embedding FROM `{proj}.{ds}.{table}` WHERE CUI IN UNNEST(@c)"
        job_config = bigquery.QueryJobConfig(query_parameters=[
            bigquery.ArrayQueryParameter("c", "STRING", batch)
        ])
        try:
            for r in client.query(query, job_config=job_config, timeout=200).result():
                embs[r.CUI] = np.array(r.embedding)
        except Exception as e:
            log(f"Embedding fetch error: {e}", "ERROR")
    
    return embs

# ========================= MAIN =========================

def main():
    """Clean example usage"""
    
    # Config
    PROJECT_ID = "your-project"
    DATASET_ID = "umls_dataset"
    API_URL = "your-api-url"
    EMBEDDING_TABLE = "cui_embeddings"
    NETWORK_PATH = "/path/to/network.pkl"
    ALLOWED_SABS = ['ICD10CM', 'ICD10PCS', 'ICD9CM', 'SNOMEDCT_US', 'LOINC']
    
    # Initialize
    system = CUIReductionSystem(PROJECT_ID, DATASET_ID, NETWORK_PATH)
    extractor = CUIExtractor(API_URL)
    
    # Process
    texts = [
        "Patient has severe pain in left knee with swelling",
        "Chest pain radiating to left arm",
        "Type 2 diabetes mellitus with hyperglycemia"
    ]
    
    for text in texts:
        log(f"Text: {text}")
        
        # Extract & filter
        extracted = extractor.extract(text)
        filtered = filter_by_sab(extracted, PROJECT_ID, DATASET_ID, ALLOWED_SABS)
        embeddings = fetch_embeddings(filtered, PROJECT_ID, DATASET_ID, EMBEDDING_TABLE)
        
        # Reduce
        result = system.reduce(filtered, embeddings, UsageContext.QUERY)
        
        # Display ONLY final results
        if result.output_cuis:
            log("Final CUIs:")
            for cui in result.output_cuis:
                score = result.scores[cui]
                log(f"  • {score.preferred_term} ({cui}) - Score: {score.completeness_score:.3f}")
        else:
            log("  No CUIs selected", "WARNING")
        
        log("")  # Blank line

if __name__ == "__main__":
    main()
